{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvVpAIyazezW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45idwjP9sLn5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSDezoagD0rG",
        "outputId": "1eeb33f6-4109-460a-b889-d0b28666679a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eFdyiFugaOP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahzlzPkbaKql",
        "outputId": "833dedf7-1ca6-4ac9-b92d-277c86829eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.63.0)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[K     |████████████████████████████████| 398 kB 76.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.5)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Collecting typing-extensions>=4.0.0\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 91.1 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 81.4 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 71.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.44.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 75.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 77.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: typing-extensions, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, PyYAML, pytorch-lightning\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.0 torchmetrics-0.7.3 typing-extensions-4.1.1 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws9y5SKK151x",
        "outputId": "3a58a539-d786-4367-94fe-2ced10c981f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n",
            "Collecting dataset\n",
            "  Downloading dataset-1.5.2-py2.py3-none-any.whl (18 kB)\n",
            "Collecting alembic>=0.6.2\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from dataset) (1.4.32)\n",
            "Collecting banal>=1.0.1\n",
            "  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (4.11.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.2->dataset) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.0.1)\n",
            "Installing collected packages: Mako, banal, alembic, dataset\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 banal-1.0.6 dataset-1.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y85soLyy1gaO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJoOCSPSDqC5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('./drive/MyDrive/Data/English_TGD2_TGD_All_data.pkl','rb') as file:\n",
        "    TGD_All_data=pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2we-aun2G_MG"
      },
      "source": [
        "#Topic prediction model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQLj3h_y6uEq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.nn import BCELoss,BCEWithLogitsLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, ElectraTokenizer, ElectraModel, ElectraConfig\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N16rMFEigwb-"
      },
      "outputs": [],
      "source": [
        "device =torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "046bdea017104e1294a01d38690de20f",
            "8a26c33a9fd7448cbc9f89a28756ac25",
            "8682e6c77db143469b2e5e984f4b5989",
            "5c85ad7fdf774e5d8364e0e864ee7b48",
            "c8210b746b6943158128a419ee5a3e8a",
            "11898f891ba6491891593fff42fb59ff",
            "1a00eb6e59104920b43ef550c1d0f2de",
            "73f240b501fd4bcb90d1149e6e27eefd",
            "c8b9e2a334f146a4bb8f0148963beaff",
            "11eef7965ce14ef3b5bd7952eaf74bf6",
            "774488e4911746b4a65bad69a6d2b201",
            "5828fdd0f15c49c3a63c7d7dac365d24",
            "5b95a9f10409456faaca721bd2c838fe",
            "d618ce88aea3422fb926c7529adde0dd",
            "fb117ae4844a4b04bfb264eb38f2f85e",
            "87ef5cf1954a4a78840c4d0223886593",
            "72fe2207b05943b294f016b8ef5ab523",
            "f60391ad8abe4a7a8ac6720cc850fbe3",
            "92571db359be40cba64c9dea3afb438d",
            "60485b8c00ac46b1b9fdea39e32a5daa",
            "cba24fcb0d6f4bf992260ad071f555ad",
            "a88d9bc4f9b140398c9a9d0a000c530e"
          ]
        },
        "id": "YmCZ94t4XqM2",
        "outputId": "1c983629-b506-440a-f166-1b3cb680db6e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "046bdea017104e1294a01d38690de20f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5828fdd0f15c49c3a63c7d7dac365d24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/51.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "pre_tained_model=ElectraModel.from_pretrained('google/electra-small-discriminator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u48iKUJIBdj9"
      },
      "outputs": [],
      "source": [
        "#model_save_path_topic=\"drive/MyDrive/Models/TopicPrediction/TGD_Classification_Concatenate_Both_Topic_Entent_Sigmoid_Less_Data.bin\" # lat utterance\n",
        "model_save_path_topic=\"drive/MyDrive/Models/TopicPrediction/TGD_Classification_Concatenate_Both_Topic_Entent_Sigmoid.bin\" # lat utterance\n",
        "tokenizer_topic_path=\"drive/MyDrive/Models/TopicPrediction/Tokenizer/\" # lat utterance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GumoKoCkyNJV"
      },
      "outputs": [],
      "source": [
        "tokenizer_topic=ElectraTokenizer.from_pretrained(tokenizer_topic_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kvQP09Oz7Az",
        "outputId": "04f4e1ee-9f2d-4ddf-a22d-72caf7b6f99e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(31238, 128)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "pre_tained_model.resize_token_embeddings(len(tokenizer_topic)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGXnGiLWrPDi"
      },
      "outputs": [],
      "source": [
        "import pickle \n",
        "with open('drive/MyDrive/Models/TopicPrediction/topic_list.pkl','rb') as f :\n",
        "  topic_list=pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31RIu85cVNx3"
      },
      "outputs": [],
      "source": [
        "class ElectraForMultiLabelSequenceClassification(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, pre_trained_model,num_labels_topics=2,num_labels_entent=2):\n",
        "    super(ElectraForMultiLabelSequenceClassification, self).__init__()\n",
        "    self.num_labels_topics = num_labels_topics\n",
        "    self.electra = pre_trained_model#Use the pretrqined model\n",
        "    self.layer1 = torch.nn.Linear(256, 1000)# add a linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.layer2  = torch.nn.Linear(1000, 2000)# add a linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.layer3  = torch.nn.Linear(2000, 3000)#change it to 5000 # add a linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.classifier_topics = torch.nn.Linear(3000, self.num_labels_topics)# add a linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.drop=torch.nn.Dropout(p=0.4)\n",
        "    self.leaky=torch.nn.ReLU()\n",
        "\n",
        "    torch.nn.init.xavier_normal_(self.classifier_topics.weight) #initialise the weight of th linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer1.weight) #initialise the weight of th linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer2.weight) #initialise the weight of th linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer3.weight) #initialise the weight of th linear layer\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels_topic=None,labels_entent=None):\n",
        "    # last hidden layer\n",
        "    last_hidden_state = self.electra(input_ids=input_ids,\\\n",
        "                                   attention_mask=attention_mask,\\\n",
        "                                   token_type_ids=token_type_ids)\n",
        "    # pool the outputs into a mean vector\n",
        "    mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
        "    l1 = self.leaky(self.layer1(mean_last_hidden_state))\n",
        "    l1=self.drop(l1)\n",
        "    l2 = self.leaky(self.layer2(l1))\n",
        "    l3 = self.leaky(self.layer3(l2))\n",
        "    l3=self.drop(l3)\n",
        "    logits_topics = torch.sigmoid(self.classifier_topics(l3))\n",
        "        \n",
        "    if labels_topic is not None:\n",
        "      loss_fct_topic = BCELoss()\n",
        "      loss1 = loss_fct_topic(logits_topics.view(-1, self.num_labels_topics),\\\n",
        "                      labels_topic.view(-1, self.num_labels_topics))\n",
        "      \n",
        "      \n",
        "      return loss1\n",
        "    else:\n",
        "      return logits_topics\n",
        "\n",
        "\n",
        "  def pool_hidden_state(self, last_hidden_state):\n",
        "    \"\"\"\n",
        "    Pool the output vectors into a single mean vector \n",
        "    \"\"\"\n",
        "    last_hidden_state = last_hidden_state[0]\n",
        "    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
        "    return mean_last_hidden_state\n",
        "    \n",
        "  \n",
        "\n",
        "# len(Y_train[0]) = 6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khzjKA6Z-z6C",
        "outputId": "a7005042-c5b5-4503-d7d0-1ad4b5e79988"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#This code is borrowed from this link : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "checkpoint = torch.load(model_save_path_topic)\n",
        "model_state_dict_topic = checkpoint['state_dict']\n",
        "model_topic = ElectraForMultiLabelSequenceClassification(pre_tained_model,num_labels_topics=model_state_dict_topic[\"classifier_topics.weight\"].size()[0])\n",
        "model_topic.load_state_dict(model_state_dict_topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrB3xNiqX8fJ"
      },
      "outputs": [],
      "source": [
        "#This code is borrowed from this link : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "def generate_predictions_topic(model, features,mask, num_labels, device=\"cpu\", batch_size=32):\n",
        "  num_iter = math.ceil(features.shape[0]/batch_size)\n",
        "  \n",
        "  pred_probs = np.array([]).reshape(0, num_labels)\n",
        "  \n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  \n",
        "  for i in range(num_iter):\n",
        "    X = features[i*batch_size:(i+1)*batch_size,:]\n",
        "    masks = mask[i*batch_size:(i+1)*batch_size,:]\n",
        "    X = X.to(device)\n",
        "    masks = masks.to(device)\n",
        "    with torch.no_grad():\n",
        "      logits = model(input_ids=X, attention_mask=masks)\n",
        "      #logits = logits.sigmoid().detach().cpu().numpy()\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      pred_probs = np.vstack([pred_probs, logits])\n",
        "  \n",
        "  return pred_probs\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qWF37be1JmT"
      },
      "outputs": [],
      "source": [
        "def tokenize_inputs_topic(liste, tokenizer, num_embeddings=512):\n",
        "    \n",
        "    outputs = tokenizer.batch_encode_plus(liste,truncation=True,return_tensors='pt',return_attention_mask=True,max_length=512, padding='max_length')\n",
        "    # convert tokenized text into numeric ids for the appropriate LM\n",
        "    input_ids =outputs.input_ids\n",
        "    \n",
        "\n",
        "    return (input_ids,outputs.attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wokzteQ194fZ"
      },
      "outputs": [],
      "source": [
        "def get_all_prediction(list_text,topic_list):\n",
        "  preds_vector=[]\n",
        "  preds_word=[]\n",
        "  for text in list_text:\n",
        "    test_input_ids,test_attention_masks=tokenize_inputs_topic([text], tokenizer_topic, num_embeddings=512)\n",
        "    pred_probs = generate_predictions_topic(model_topic, test_input_ids,test_attention_masks, 2464, device=device, batch_size=32)\n",
        "    prob=np.round(pred_probs)\n",
        "    prob=list(prob[0])\n",
        "    preds_vector.append(prob)\n",
        "\n",
        "    pred_probs=prob\n",
        "    indexes=[i for i, v in enumerate(prob) if v==1]\n",
        "    predicted_topics=\" \".join(topic_list[x] for x in indexes)\n",
        "    predicted_topics=\" <topic> \"+predicted_topics+\" </topic>\"\n",
        "    preds_word.append(predicted_topics)\n",
        "  \n",
        "  return preds_vector,predicted_topics\n",
        "  \n",
        "#preds,preds_word=get_all_prediction(test_data,topic_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "089ppqyQjWrG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tGS7LHsWmm9E",
        "outputId": "6f5df0e7-535a-4993-d876-2f42aebbde54"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' <topic> moving talk </topic>'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t=\"<seeker> how about you recommend me a moving movie first ?\"\n",
        "preds,preds_word=get_all_prediction([t],topic_list)\n",
        "preds_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM8erREElPRa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJYKONJ6Ig-2"
      },
      "source": [
        "#Profile generation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h86vCWe7Iitn"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5TokenizerFast as T5Tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23ciFrWQEYM0"
      },
      "outputs": [],
      "source": [
        "path_tokenizer=\"./drive/MyDrive/Summarization/PresonaChat-ProfileGeneration_whith_t5/tokenizer\"\n",
        "path_model=\"./drive/MyDrive/Summarization/PresonaChat-ProfileGeneration_whith_t5/model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVaSPFwHEYM1"
      },
      "outputs": [],
      "source": [
        "tokenizer_t5=T5Tokenizer.from_pretrained(path_tokenizer)\n",
        "trained_model_t5=T5ForConditionalGeneration.from_pretrained(path_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6d_JJczJJYA"
      },
      "outputs": [],
      "source": [
        "text=\"hello what are you doing today ? i am good , i just got off work and tired , i have two jobs . i just got done watching a horror movie i rather read , i've read about 20 books this year . wow ! i do love a good horror movie . loving this cooler weather but a good movie is always good . yes ! my son is in junior high and i just started letting him watch them too i work in the movies as well . neat ! ! i used to work in the human services field yes it is neat , i stunt double , it is so much fun and hard work . yes i bet you can get hurt . my wife works and i stay at home nice , i only have one parent so now i help out my mom . i bet she appreciates that very much . she raised me right , i am just like her . my dad was always busy working at home depot\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSYP0R-QEYM1"
      },
      "outputs": [],
      "source": [
        "def summarize(text,trained_model,tokenizer_t5):\n",
        "  text_encoding=tokenizer_t5(text,padding=\"max_length\",max_length=512,truncation=True,return_attention_mask=True,return_tensors=\"pt\")\n",
        "  generated_ids=trained_model.generate(\n",
        "      input_ids=text_encoding[\"input_ids\"],\n",
        "      attention_mask=text_encoding[\"attention_mask\"],\n",
        "      max_length=150, \n",
        "      num_beams=15,\n",
        "      early_stopping=True,\n",
        "      repetition_penalty=2.5,\n",
        "      length_penalty=1.0,\n",
        "  )\n",
        "  preds=[tokenizer_t5.decode(gen_id,skip_special_tokens=True,clean_up_tokenization_space=True) for gen_id in generated_ids]\n",
        "  return \" \".join(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDdAfGEAKtVB"
      },
      "source": [
        "# Personality prediction model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "eb5def54e83443708d42edec24128479",
            "9c55a11ad21748f18571f159706b52b9",
            "104a4160dc2f444db52b86df625ff176",
            "17e1e7fba3a7455abb90540888fee672",
            "7ed3e6ab3eac44ada0f5e74f1d7fcc9f",
            "46be53ad1a17403494f5bcdfc09de0f9",
            "9a07d78c0cf84663a574f1a42487c062",
            "e32912cf22724b3897d9bef95511695a",
            "78023d8db1b645c4be11952645290ccb",
            "d5f496e7ab0148eb89c9dcf37674cf1d",
            "f6c9a7dacd7048ddb5afa710cd2919b5",
            "fe576e433c4d4d788c86d4f6c6838788",
            "a73aa951444248cca267d1a55d0e4cf1",
            "db8d122b53d3466cb792a6ebf72c876d",
            "fcee081f09114b829c88090c216886a8",
            "4dcf88109f20410f8962ad27c770e277",
            "e22e66afc7954f3d9bdeb2f0817d82ce",
            "eace18d94c6c4adeab4d5560f4fb7963",
            "7227f9ffc0584bf9a690363409ef423c",
            "423f3cfe34a04827b15b6ff6f8e93ffa",
            "b8c204a4641641a5b7f0e54c1c6473ac",
            "db8af3cd6df849aaa51c87d4d9eca893"
          ]
        },
        "id": "SbFJsjo6KydH",
        "outputId": "32976024-3009-441d-fda2-4ff06a87b741"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb5def54e83443708d42edec24128479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe576e433c4d4d788c86d4f6c6838788",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name='google/electra-small-discriminator'\n",
        "\n",
        "tokenizer_personality = ElectraTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FS-DUk1gOQ90"
      },
      "outputs": [],
      "source": [
        "from torch.nn import BCEWithLogitsLoss,MSELoss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw4vZGVWMQr_"
      },
      "outputs": [],
      "source": [
        "class ElectraSharedWeights_Multi_Task(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, r_num_labels=2,c_num_labels=2):\n",
        "    super(ElectraSharedWeights_Multi_Task, self).__init__()\n",
        "    self.c_num_labels = c_num_labels#The number of the classification labels whiche are 4 labels to use them as the final size for  the final linear layer\n",
        "    self.r_num_labels = r_num_labels#The number of the regression labels whiche are 5 labelsto use them as the final size for  the final linear layer\n",
        "    self.electra = ElectraModel.from_pretrained(model_name)#Instanciate  the pretrained model\n",
        "    self.layer1 = torch.nn.Linear(256, 150)# add The first linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.layer2  = torch.nn.Linear(150, 100)# add the second linear layer on top of the first one\n",
        "    self.layer3  = torch.nn.Linear(100, 50)# add the third linear layer on top of the second one\n",
        "    #self.normilizer1  = torch.nn.BatchNorm1d(256)# add the normalizer to the electra values\n",
        "    #self.normilizer2  = torch.nn.BatchNorm1d(100)# add the  normilizer layer onto the second layer values\n",
        "    #All the previous layers will be shared by the last separate two layers (classifier layer and regressor layer)\n",
        "\n",
        "    self.classifier = torch.nn.Linear(50, c_num_labels)# add the final linear layer for classification on top of the third layer   \n",
        "    self.regressor = torch.nn.Linear(50, r_num_labels)# add the final linear layer for regression on top of the third layer \n",
        "    self.drop=torch.nn.Dropout(p=0.4)# Define a dropout layer to overpass the overfitting during the training phase\n",
        "    self.leaky=torch.nn.LeakyReLU()# Use the Leaky Relu activation function as the ;ain activation function for the shared layers\n",
        "\n",
        "\n",
        "\n",
        "    #In order to train our models the weights need to be initialized, because if they were at 0, then the model will not be optimized so we need to\n",
        "    # inilize them. The most popular way to inisialize the weights is to use the Xavier initializer\n",
        "    torch.nn.init.xavier_normal_(self.layer1.weight) #initialise the weight of the first linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer2.weight) #initialise the weight of the second linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer3.weight) #initialise the weight of the third linear layer\n",
        "    torch.nn.init.xavier_normal_(self.classifier.weight) #initialise the weight of the classification layer\n",
        "    torch.nn.init.xavier_normal_(self.regressor.weight) #initialise the weight of th regression layer\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels_r=None,labels_c=None):\n",
        "    #Now that we defined the architecture and initialized the weights we need to define the forward function\n",
        "    #and how each defined variable will be used in the architecture\n",
        "\n",
        "    # last hidden layer\n",
        "    #for ech row we will use the ELECTRa model to create an embedding vector given the tokenized input\n",
        "    Electra_hidding_state = self.electra(input_ids=input_ids,\\\n",
        "                                   attention_mask=attention_mask,\\\n",
        "                                   token_type_ids=token_type_ids)\n",
        "    contextual_embedding = Electra_hidding_state[0]\n",
        "    contextual_embedding = torch.mean(contextual_embedding, 1)\n",
        "    #contextual_embedding=self.normilizer1(contextual_embedding)\n",
        "    # pool the outputs into a mean vector\n",
        "    cl1 = self.leaky(self.layer1(contextual_embedding))\n",
        "    cl1=self.drop(cl1)\n",
        "    cl2 = self.leaky(self.layer2(cl1))\n",
        "    #cl2 = self.normilizer2(cl2)\n",
        "    cl3 = self.leaky(self.layer3(cl2))\n",
        "    cl3=self.drop(cl3)\n",
        "\n",
        "    #All the previous weights will be shared by both last layers (classifier and regresor) \n",
        "    clogits = self.classifier(cl3)# The classification results(MBTI Labels) given the shared weights\n",
        "\n",
        "    rlogits = self.regressor(cl3)# The regression results(BIG5 labels) given the shared weights\n",
        "\n",
        "\n",
        "    # Due to the fact that we have a multi-task learning model then we will have two different losses\n",
        "    # one to compute the classification loss and the other is to compute the regression loss\n",
        "    # We will use the BCE version for the classification loss and the MSE for the regression loss\n",
        "        \n",
        "    closs_fct =BCEWithLogitsLoss()# Classification loss\n",
        "    rloss_fct = MSELoss()# Regression loss\n",
        "\n",
        "    if ((labels_r is not None) and (labels_c is not None)):\n",
        "\n",
        "  \n",
        "      closs = closs_fct(clogits.view(-1, self.c_num_labels),\\\n",
        "                        labels_c.view(-1, self.c_num_labels))\n",
        "      rloss=rloss_fct(rlogits.view(-1, self.r_num_labels),\\\n",
        "                        labels_r.view(-1, self.r_num_labels))\n",
        "      #Because a model need to have one loss function to be trained on and be cause we need to minimise both regression and classification loss\n",
        "      #we create a combination of the regression loss and the classification loss by summing them and deviding by 2\n",
        "      #By combining both losses  into a one loss we will force the model to minimize the combination loss wich will lead to the minimization of the \n",
        "      #regression and the classification loss (minimizing their sum will lead to minimizing their original values)\n",
        "      loss=(rloss+closs)/2\n",
        "      return loss\n",
        "    else:\n",
        "      return clogits,rlogits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_glEZ1euMw-e"
      },
      "outputs": [],
      "source": [
        "model_save_path=\"./drive/MyDrive/Models/Pandora_Personality/SeedDoubleHead_SharedWeights_20epochs_Electra.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEkLbrn0wCmT",
        "outputId": "2b2b37f7-ce1d-4afb-f2d2-58fa3a5f1784"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#This code is borrowed from this link : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "checkpoint = torch.load(model_save_path)\n",
        "model_state_dict = checkpoint['state_dict']\n",
        "model_personality = ElectraSharedWeights_Multi_Task(5,4)\n",
        "model_personality.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snHLwolINIO6"
      },
      "outputs": [],
      "source": [
        "def Input_Tokenization_personality(liste, tokenizer):\n",
        "    \n",
        "    outputs = tokenizer.batch_encode_plus(liste,padding=True,truncation=True,return_tensors='pt',return_attention_mask=True)    \n",
        "\n",
        "    return (outputs.input_ids,outputs.attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pXalaLbMuER"
      },
      "outputs": [],
      "source": [
        "#This code is borrowed from this link : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "def Predict(model,tokenizer, text, num_label_c,num_label_r, device=\"cpu\", batch_size=32):\n",
        "  features,mask=Input_Tokenization_personality([text], tokenizer)\n",
        "  num_iter = math.ceil(features.shape[0]/batch_size)# define the number of iteration in all the data by batches\n",
        "  features.to(device)\n",
        "  mask.to(device)\n",
        "  model.eval() #Indicate that we will use the model to evaluation purposes\n",
        "\n",
        "  c_pred_probs = np.array([]).reshape(0, num_label_c)# Create dummpy classification predictions 'all 0' vectors that we will modify\n",
        "  r_pred_probs = np.array([]).reshape(0, num_label_r)# Create dummpy regression predictions 'all 0' vectors that we will modify\n",
        "  model.to(device)\n",
        "  d={}\n",
        "  \n",
        "  for i in range(num_iter):# for each batch\n",
        "    X = features[i*batch_size:(i+1)*batch_size,:]#Get the features of the passed data\n",
        "    masks = mask[i*batch_size:(i+1)*batch_size,:]#Get the masks of the passed data\n",
        "    X = X.to(device)#transfer them to the device 'exmp cuda'\n",
        "    masks = masks.to(device)#transfer them to the device 'exmp cuda'\n",
        "    with torch.no_grad():\n",
        "      logits_c,logits_r = model(input_ids=X, attention_mask=masks) # predict the values of the passed batch of data\n",
        "      #logits = logits.sigmoid().detach().cpu().numpy()\n",
        "      logits_c = logits_c.sigmoid().detach().cpu().numpy()# for the classification head we will aplly a sigmoid function as like we said the classification labels are binary labels\n",
        "      c_pred_probs = np.vstack([c_pred_probs, logits_c])# stack them to the pr-defined dummy classification variable\n",
        "      logits_r = logits_r.detach().cpu().numpy()# For the regression values wi well use directly the linear layer output because the regression labels are real values\n",
        "      r_pred_probs = np.vstack([r_pred_probs, logits_r])# stack them to the pr-defined dummy regression variable\n",
        "  d['class_pred']=np.round(c_pred_probs) # to get binary values for the sigmoids probability values we will use the .round() function for the classification results\n",
        "  d['reg_pred']=r_pred_probs\n",
        "  \n",
        "  return d\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUz9MqvTlPgJ"
      },
      "source": [
        "#Next movie to watch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkoZb1qerU6L"
      },
      "outputs": [],
      "source": [
        "from transformers import ElectraTokenizerFast, ElectraForMaskedLM,ElectraConfig, ElectraTokenizer\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzZEjrdRlR0n"
      },
      "outputs": [],
      "source": [
        "class Electra4RecWithTGD_OnlyNextItemToPredict(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Electra4RecWithTGD_OnlyNextItemToPredict, self).__init__()\n",
        "    \n",
        "    model=DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
        "    model.resize_token_embeddings(len(tokenizer_4rec))\n",
        "\n",
        "\n",
        "    model_mask_last=DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
        "    model_mask_last.resize_token_embeddings(len(tokenizer_4rec))\n",
        "\n",
        "\n",
        "    self.electra = model\n",
        "    self.electra_mask_last = model_mask_last\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "   \n",
        "  def forward(self, input_ids, token_type_ids=None,attention_mask=None, labels=None,input_ids_mask_last=None, token_type_ids_mask_last=None,attention_mask_mask_last=None, labels_mask_last=None):\n",
        "    #Now that we defined the architecture and initialized the weights we need to define the forward function\n",
        "    #and how each defined variable will be used in the architecture\n",
        "    \n",
        "    \n",
        "    \n",
        "    position_ids=torch.arange(start=0, end = input_ids.shape[1], step=1).expand_as(input_ids).to(device)\n",
        "    \n",
        "    \n",
        "    #position_sinusoidal_embeddings = np.array([[pos / np.power(10000, 2 * (j // 2) / input_ids.shape[1]) for j in range(input_ids.shape[1])] for pos in range(input_ids.shape[0])])\n",
        "    #position_ids=position_sinusoidal_embeddings\n",
        "   \n",
        "   \n",
        "    # last hidden layer\n",
        "    #for ech row we will use the ELECTRa model to create an embedding vector given the tokenized input\n",
        "\n",
        "\n",
        "    #Electra predfoned positions\n",
        "\n",
        "    MLM_outputs = self.electra(input_ids, attention_mask=attention_mask,labels=labels)\n",
        "    self.electra_mask_last.state_dict()['vocab_layer_norm.bias']=self.electra.state_dict()['vocab_layer_norm.bias']\n",
        "\n",
        "    MLM_outputs_mask_last= self.electra_mask_last(input_ids_mask_last, attention_mask=attention_mask_mask_last,labels=labels_mask_last)\n",
        "\n",
        "    \n",
        "    #withour position  embdedding\n",
        "    #MLM_outputs = self.electra(input_ids, attention_mask=attention_mask,labels=labels)\n",
        "\n",
        "    \n",
        "\n",
        "    if ((labels is not None) ):\n",
        "\n",
        "\n",
        "      loss=(MLM_outputs.loss + MLM_outputs_mask_last.loss)\n",
        "      return loss\n",
        "    else:\n",
        "      return MLM_outputs.logits,MLM_outputs_mask_last.logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffsz2bVJ7Spz"
      },
      "outputs": [],
      "source": [
        "path='drive/MyDrive/Models/NextMovie/DistilBert_TGD_Ensemble_no_BIG5_last_masked_and_NormalMask_OnlyNextItemToPredict.bin'\n",
        "path_tokenizer='drive/MyDrive/Models/NextMovie/Tokenizer/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17Epl3K29DOx"
      },
      "outputs": [],
      "source": [
        "tokenizer_4rec = DistilBertTokenizer.from_pretrained(path_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "213350da35874dd39b218c8655d01c0a",
            "e34a85c3aa254b3795e18bee7df76a6d",
            "aaa0577cc3564419adc62805393c783b",
            "2a9fe0d551664129b45923a59ca9a428",
            "f45ab81220e74bf681b90549e56d67ca",
            "30eee08690264b75b960ed18b57823f8",
            "d271eb29164a4703b1bac30f2ec74bc2",
            "3ea79b701868421c90dc0e6b9e77e9f7",
            "e99ea3ccfd984d7488528f405f796f43",
            "3a05b82bd0234ec081a7675d30953700",
            "201e035152364c6a8ef83a74af664067",
            "99ff89a794044a27832ee84052fde5b6",
            "5a343b01af2e4c4682ab079718b5ebe0",
            "d4abc76ac26a4044bda1bf4a9a3c5a65",
            "93471d7f306b4eec8fb3904b7e86ce2c",
            "50862acb7f164eca953b5cc8395f2978",
            "b611decc9f584cd7b49daa86e8fdadbf",
            "1351a203b4c24bf28d976fb0593bdcbe",
            "4ce40ce5a9cf48719d4728a8e3dc0445",
            "9e3f1ae2d0a942068a80e564f57fae2b",
            "24df6c7c418c4e5e99d341d91e7f8f42",
            "f39bc0eeaff949f5b7688664d3bf0245"
          ]
        },
        "id": "SSwTHkdEiauX",
        "outputId": "2f8d7ab6-8d44-47fc-8bee-3fcc0c20e100"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "213350da35874dd39b218c8655d01c0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99ff89a794044a27832ee84052fde5b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#This code is borrowed from this link : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "checkpoint = torch.load(path)\n",
        "model_state_dict = checkpoint['state_dict']\n",
        "model_movie = Electra4RecWithTGD_OnlyNextItemToPredict()\n",
        "model_movie.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIF0rY-SMW0a"
      },
      "outputs": [],
      "source": [
        "def sequence_Input_Tokenization_movie_prediction(liste, tokenizer):\n",
        "    \n",
        "    outputs = tokenizer(liste,truncation=True,return_tensors='pt',return_attention_mask=True,max_length=512, padding='max_length')    \n",
        "    outputs['labels']=outputs.input_ids.detach().clone()\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqi2I5BfMdYw"
      },
      "outputs": [],
      "source": [
        "#This code is borrowed from this link : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "def Predict_Movie(sequences,model, tokenizer_m, device=\"cpu\", batch_size=32):\n",
        "  num_iter = math.ceil(np.array(sequences).shape[0]/batch_size)# define the number of iteration in all the data by batches\n",
        "  model.eval() #Indicate that we will use the model to evaluation purposes\n",
        "  model.to(device)\n",
        "  d={}\n",
        "  \n",
        "  IndexToKey={ value:key for key,value in tokenizer_m.get_vocab().items() }\n",
        "  for i in range(num_iter):\n",
        "    inputs_i=tokenizer_m(sequences[i],return_tensors='pt')\n",
        "    inputs_ids=inputs_i.input_ids.to(device)\n",
        "    inputs_mask=inputs_i.attention_mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        #output= model(inputs_ids,inputs_mask,input_ids_mask_last=inputs_ids,attention_mask_mask_last=inputs_mask)# predict the values of the passed batch of data\n",
        "        output= model(input_ids=inputs_ids,attention_mask=inputs_mask,input_ids_mask_last=inputs_ids,attention_mask_mask_last=inputs_mask)# predict the values of the passed batch of data\n",
        "        #logits = logits.sigmoid().detach().cpu().numpy()\n",
        "        out=torch.argmax(output[0],dim=-1).to(device)\n",
        "        \n",
        "        ch=''\n",
        "        \n",
        "        for ind in list(out.detach().tolist()[0]):\n",
        "          ch=ch+IndexToKey[ind]+' '\n",
        "  d['MLM_movie_prediction']=ch.split()\n",
        "  \n",
        "  return d['MLM_movie_prediction'][-2]\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNzwPD3z_zoj"
      },
      "source": [
        "# Dialog Generation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMkhQo-hBa0J"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4CqdM7d-u-t"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bym3_tybI3M"
      },
      "outputs": [],
      "source": [
        "def remove_movie_from_path_goal(TGD_All_data,typee='train'):\n",
        "  for i, dial in enumerate(TGD_All_data[typee]):\n",
        "    goal_path=dial['goal_path']\n",
        "    for k, v in goal_path.items():\n",
        "      v=[x for x in v if x[0]!='@']\n",
        "      goal_path[k]=v\n",
        "    \n",
        "    TGD_All_data[typee][i]['goal_path']=goal_path\n",
        "  return TGD_All_data[typee]\n",
        "\n",
        "TGD_All_data['train']=remove_movie_from_path_goal(TGD_All_data,typee='train')\n",
        "TGD_All_data['test']=remove_movie_from_path_goal(TGD_All_data,typee='test')\n",
        "TGD_All_data['valid']=remove_movie_from_path_goal(TGD_All_data,typee='valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzQYBqycsSMv"
      },
      "outputs": [],
      "source": [
        "def create_entent_topic(TGD_All_data=TGD_All_data,typee=\"train\"):\n",
        "\n",
        "  topic_list=TGD_All_data[\"real_topics\"].values()\n",
        "  for i,dial in enumerate(TGD_All_data[typee]):\n",
        "    goal_path=dial[\"goal_path\"]\n",
        "    new_goal_path={}\n",
        "    \n",
        "    for k,v in goal_path.items():\n",
        "      topics=[x for x in v if x in topic_list]\n",
        "      intents=[x for x in v if x not in topic_list]\n",
        "      if(len(topics)==0):\n",
        "        topics=[\"no-topic\"]\n",
        "      new_goal_path[k]={\"intents\":intents,\"topics\":intents+topics}\n",
        "    TGD_All_data[typee][i][\"goal_path\"]=new_goal_path\n",
        "\n",
        "  return TGD_All_data\n",
        "TGD_All_data=create_entent_topic(TGD_All_data=TGD_All_data,typee=\"train\")\n",
        "TGD_All_data=create_entent_topic(TGD_All_data=TGD_All_data,typee=\"test\")\n",
        "TGD_All_data=create_entent_topic(TGD_All_data=TGD_All_data,typee=\"valid\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xCQWHwMMT5s"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "def create_path_included_data(data,typee='valid'):\n",
        "  data_dialogue_rows=[]\n",
        "  mentioned_movies=[]\n",
        "  movie_history_watching=[]\n",
        "  for i,dial in enumerate(data[typee]):\n",
        "    goal_path=dial['goal_path']\n",
        "    messages=dial['messages']\n",
        "    mentionMovies=dial[\"mentionMovies\"]\n",
        "    movies_interaction=dial[\"user_history_movies_interaction_ids\"]\n",
        "    movie_history_watching.append(movies_interaction)\n",
        "\n",
        "\n",
        "    visited_profiles=[]\n",
        "    for j in range(1):\n",
        "      profile_list=dial[\"user_profile\"]\n",
        "      personality_list=dial[\"BIG5\"]\n",
        "      shuffled_profile=random.sample(profile_list,len(profile_list))\n",
        "      while shuffled_profile in visited_profiles:\n",
        "        shuffled_profile=random.sample(profile_list,len(profile_list))\n",
        "      personality= \" \".join(str(int(p)) for p in personality_list )\n",
        "      \n",
        "      profile=\" .\".join(p for p in shuffled_profile )\n",
        "      lines=[]\n",
        "      lines.append('<big5> '+personality+\" </big5>\")\n",
        "\n",
        "      \n",
        "      lines.append('<profile> '+profile+\" </profile>\")\n",
        "      movies_to_add=[]\n",
        "      '''if len(movies_interaction)==0:\n",
        "        movies_to_add=[\" \"]*3\n",
        "\n",
        "      if len(movies_interaction)==1:\n",
        "        movies_to_add=[movies_interaction[-1]]*3\n",
        "\n",
        "      if len(movies_interaction)==2:\n",
        "        movies_to_add=list(movies_interaction)+[movies_interaction[-1]]\n",
        "\n",
        "      if len(movies_interaction)>2:\n",
        "        movies_to_add=list(movies_interaction[-3:])'''\n",
        "\n",
        "      for i,v in enumerate(messages):\n",
        "        index=i+1\n",
        "        if index in mentionMovies:\n",
        "          curenntmovi=mentionMovies[index][\"id\"]\n",
        "          #print(curenntmovi)\n",
        "          movies_to_add.append(curenntmovi)\n",
        "          #print(movies_to_add)\n",
        "          last_three=movies_to_add[-3:]\n",
        "          random.shuffle(last_three)\n",
        "          concatenated_movies= \" \".join(x for x in last_three)\n",
        "          #lines[-1]=lines[-1]+\" <movies> \"+curenntmovi+\" </movies>\"\n",
        "          m='<'+v['role'].lower()+'>'+' '+v['content']\n",
        "\n",
        "\n",
        "        else:\n",
        "          m='<'+v['role'].lower()+'>'+' '+v['content']\n",
        "        m=m+' <topic> '+' '.join(x for x in goal_path[v['local_id']][\"topics\"] )+\" </topic> \"\n",
        "        m=re.sub(' +', ' ', m).strip()\n",
        "        if(\"@\" in m ):\n",
        "          lin= np.array([word for word in m.split(\" \") ])\n",
        "          indexes=[i for i,v in enumerate(lin) if v[0]==\"@\"]\n",
        "          elements=[x for x in list(lin[indexes]) if x is not None]\n",
        "          mentioned_movies=mentioned_movies+elements\n",
        "\n",
        "        lines.append(m)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "      data_dialogue_rows.append(lines)\n",
        "    \n",
        "  return data_dialogue_rows,mentioned_movies,movie_history_watching\n",
        "    \n",
        "\n",
        "train_rows,train_mentioned_movies,train_movie_history_watching=create_path_included_data(TGD_All_data,typee='train')   \n",
        "test_rows,test_mentioned_movies,test_movie_history_watching=create_path_included_data(TGD_All_data,typee='test')   \n",
        "valid_rows,valid_mentioned_movies,valid_movie_history_watching=create_path_included_data(TGD_All_data,typee='valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi-P6epMCCgJ"
      },
      "outputs": [],
      "source": [
        "path_model='drive/MyDrive/Models/DialogGeneration/Prompt_based_TGD_small_keep_all_data2.bin'\n",
        "path_tokenizer='drive/MyDrive/Models/DialogGeneration/Tokenizer/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TxMdedpFF7m"
      },
      "outputs": [],
      "source": [
        "tokenizer_gpt = AutoTokenizer.from_pretrained(path_tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l2SDqiU2hIR"
      },
      "outputs": [],
      "source": [
        "class DialogGPT(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self,tokenizer):\n",
        "    super(DialogGPT, self).__init__()\n",
        "    \n",
        "    self.dialogGPT = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-small')\n",
        "    self.dialogGPT.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "   \n",
        "\n",
        "   \n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels=None): \n",
        "   \n",
        "        \n",
        "    outputs = self.dialogGPT(input_ids,attention_mask=attention_mask, labels=labels)\n",
        "    loss = outputs[0]\n",
        "      \n",
        "      \n",
        "    return loss\n",
        "\n",
        "\n",
        "  def pool_hidden_state(self, last_hidden_state):\n",
        "    \"\"\"\n",
        "    Pool the output vectors into a single mean vector \n",
        "    \"\"\"\n",
        "    last_hidden_state = last_hidden_state[0]\n",
        "    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
        "    return mean_last_hidden_state\n",
        "    \n",
        "  \n",
        "\n",
        "# len(Y_train[0]) = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQjxkp9_giYS"
      },
      "outputs": [],
      "source": [
        "#model_save_path_gpt=\"drive/MyDrive/Models/DialogGeneration/Prompt_based_TGD_small_keep_all_data.bin\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f21de76db49a45e087a35880a61bb814",
            "b7c3da56c93c4f488e8813fc95588d6f",
            "3e220e9c132d48be869cb9fbaa4f7c30",
            "fe0f2e1b254d4073a8d3d8d091dcfc37",
            "d6c2559efc8c4e988ba7b29e672ec8bd",
            "8f002d06ef96414581ae4a7a9b676567",
            "b020942d5ca4485da302432e1e4e6722",
            "50f6bc0eba3941dc85dc206e1f19fbf3",
            "c3d82f9c1a2e413e8bbd4ab3da4201c3",
            "0d3a81420d9d41079e963833ddb0e65a",
            "076ff170b97f42d481172e90ae4b45d9",
            "0131f67090dd407f86b3722c6ad77ddb",
            "73d862abb92e4b46995b82502646c642",
            "0bd189ca5431413e9b451ed16fcbe73f",
            "a05d2632d3694b019880d9f3ab198c03",
            "c0479d26477149df88290117cc225e78",
            "6d98730ddfed4832b90a29b38e9071cd",
            "bfbdb81a25b241c2bdc3d7d1d528e34e",
            "d1b31de53ab346a58a5a9cee889e1bd1",
            "6087e86a784c49c9992359bf12664b35",
            "b56b32b1b291439abe98baa9ff823b1b",
            "df4e9e0c679c4a8fbd5a997f9b92d215"
          ]
        },
        "id": "KcHenJRMEnwj",
        "outputId": "9619b490-4600-4d1a-b7ed-c3945b15f760"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f21de76db49a45e087a35880a61bb814",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/641 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0131f67090dd407f86b3722c6ad77ddb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DialogGPT(\n",
              "  (dialogGPT): GPT2LMHeadModel(\n",
              "    (transformer): GPT2Model(\n",
              "      (wte): Embedding(86054, 768)\n",
              "      (wpe): Embedding(1024, 768)\n",
              "      (drop): Dropout(p=0.1, inplace=False)\n",
              "      (h): ModuleList(\n",
              "        (0): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=768, out_features=86054, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#This code is borrowed from this link : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "checkpoint_gpt = torch.load(path_model)\n",
        "model_state_dict_gpt = checkpoint_gpt['state_dict']\n",
        "model_gpt = DialogGPT(tokenizer=tokenizer_gpt)\n",
        "model_gpt.load_state_dict(model_state_dict_gpt)\n",
        "model_gpt.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhUWEeP2VXtO"
      },
      "source": [
        "# last utterance topic prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4V0OVo6OiMG"
      },
      "outputs": [],
      "source": [
        "movies_dict= TGD_All_data['all_movies']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDqd7s9SDZIS"
      },
      "outputs": [],
      "source": [
        "def tokenize_inputs(liste, tokenizer, num_embeddings=1024):\n",
        "    \n",
        "    outputs = tokenizer.batch_encode_plus(liste,truncation=True,return_tensors='pt',return_attention_mask=True,max_length=num_embeddings, padding='max_length')\n",
        "    # convert tokenized text into numeric ids for the appropriate LM\n",
        "    input_ids =outputs.input_ids\n",
        "    outputs[\"labels\"]=input_ids\n",
        "    \n",
        "\n",
        "    return input_ids,outputs.attention_mask\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMB_GruUuLXs"
      },
      "outputs": [],
      "source": [
        "i=5\n",
        "persona_0=test_rows[i][0]+tokenizer_gpt.eos_token+test_rows[i][1]\n",
        "conv_0=test_rows[i][2:]\n",
        "movie_history_watching=test_movie_history_watching[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol_G1bWErvn2"
      },
      "source": [
        "# changing the topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEaf8d3C0QnY"
      },
      "outputs": [],
      "source": [
        "i=5\n",
        "persona_0=test_rows[i][0]+tokenizer_gpt.eos_token+test_rows[i][1]\n",
        "conv_0=test_rows[i][2:]\n",
        "movie_history_watching=test_movie_history_watching[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "i4M3G_AcBcQb",
        "outputId": "5c7ded9f-eaf0-435c-965b-b3751f67546b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<big5> 28 79 21 50 60 </big5><|endoftext|><profile> i like sports .the place i want to travel most is india .i like animation .i like kids .i like love very much .i like to live on the ground .i like writing love letters very much .i like music very much .i think i am a loud voice .i really want to have sincere feelings </profile>'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "persona_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzc3JrXKVB8X",
        "outputId": "04bffb81-d95b-47e4-a7fd-c49dc042fab5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['song of sunshine',\n",
              " 'air evacuation',\n",
              " 'the teacher and the stray cat',\n",
              " 'legend no. 17',\n",
              " 'spiritual grace',\n",
              " 'the mind of the han and han princess',\n",
              " 'lemon mouth',\n",
              " 'undead debt collector',\n",
              " 'live with integrity',\n",
              " 'dumb boy']"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[movies_dict[x]['name']for x in movie_history_watching[-10:]]\n",
        "#lemon mouth : children movie \n",
        "#the teacher and the stray cat : comedy family\n",
        "#dumb boy: family movie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RpEggpUruch",
        "outputId": "e3b3f57e-adbd-43fc-8221-110dff3e871f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>DialoGPT:      how are things?\n",
            ">>DialoGPT:      no problem, i recommend you to watch \u001b[6;30;42mred light\u001b[0m, which is a story about love and death.\n",
            ">>DialoGPT:      of course, i recommend a comedy movie for you.\n",
            ">>DialoGPT:      then i recommend a horror comedy movie to you. have you ever watched \u001b[6;30;42mhorror wax museum\u001b[0m? it's a bit scary, but it's still very funny.\n",
            ">>DialoGPT:      no, i don’t have one, but i have watched a lot of horror movies. would you like to recommend a horror movie to you?\n",
            ">>DialoGPT:      of course, i would recommend a horror and thriller movie to you. you will like \u001b[6;30;42mhorror wax museum\u001b[0m. the ending is a bit unexpected, but the plot is still very good.\n",
            ">>DialoGPT:      then i recommend a movie about horror and horror. have you seen \u001b[6;30;42mhorror wax museum\u001b[0m? the plot is very exciting, and the actors' acting skills are also very good. it is also a horror movie. it is worth watching. it is a rare horror movie that is not bloody and not bloody. it is worth recommending.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Beam search Decoding\n",
        "next_movie_to_watch=\"\"\n",
        "previous_string=persona_0+tokenizer_gpt.eos_token +'<recommender>'\n",
        "persona_ids=tokenizer_gpt.encode(previous_string , return_tensors='pt').to(device)\n",
        "new_user_input_ids=persona_ids\n",
        "previous_interactions=\"\"\n",
        "#print(f'previous string: {previous_string}')\n",
        "# Let's chat for 5 lines\n",
        "for step in range(100):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    # print(new_user_input_ids)\n",
        "    #chat_history_ids= tokenizer.encode(persona)\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = new_user_input_ids\n",
        "\n",
        "    #print(f\"bot_input_ids : {tokenizer_gpt.decode(bot_input_ids[0])}\")\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens, \n",
        "    chat_history_ids = model_gpt.dialogGPT.generate(\n",
        "        bot_input_ids, max_length=1000,\n",
        "        pad_token_id=tokenizer_gpt.eos_token_id,\n",
        "        no_repeat_ngram_size=5,\n",
        "        num_beams=5,\n",
        "        early_stop=True\n",
        "\n",
        "        \n",
        "    )\n",
        "    #print(f'chat history id : {tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0])}')\n",
        "\n",
        "#        do_sample=True,\n",
        "\n",
        "#num_return_sequences=3\n",
        "    \n",
        "    # pretty print last ouput tokens from bot\n",
        "    response=tokenizer_gpt.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "    #print(f'response oroginale ; {response}')\n",
        "\n",
        "\n",
        "    if \"<topic>\" in response:\n",
        "        in_response=response\n",
        "        response=response.split()\n",
        "        response=response[:response.index(\"<topic>\")]\n",
        "        response=\" \".join(x for x in response)\n",
        "    \n",
        "\n",
        "      \n",
        "    if '@' in response:\n",
        "      movie_pred=re.findall(r\"@[0-9]+\",response)[0]\n",
        "      previous_interactions=previous_interactions+' '+movie_pred\n",
        "\n",
        "\n",
        "    #print(f\"see all the dialogue {all_dialogue_text}\")\n",
        "    #print(f\"Fed input to the topic prediction {response}\")\n",
        "    _,topics=get_all_prediction([response],topic_list)\n",
        "    #_,topics=get_all_prediction_only_topic([topic_text_without_big5_personality],topic_list,intent_tokens)\n",
        "    #print(f\" predict the topic {topics}\")\n",
        "    \n",
        "    if '@' in response:\n",
        "      movie_pred=re.findall(r\"@[0-9]+\",response)[0]\n",
        "      #response=response+f\" you may also like {movies_dict[next_movie_to_watch]['name']} based on your previous history of watching.\"\n",
        "      print(\">>DialoGPT:      {}\".format(re.sub(movie_pred, \"\\x1b[6;30;42m\"+movies_dict[movie_pred]['name']+\"\\x1b[0m\", response)))\n",
        "    else:\n",
        "      print(\">>DialoGPT:      {}\".format(response))\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    user_utterance='<seeker> '+input(\">> User:         \")\n",
        "    _,topics_user_utterance=get_all_prediction([user_utterance],topic_list)\n",
        "    #print(f\"\\n User topic {topics_user_utterance}\\n\")\n",
        "    user_utterance=user_utterance\n",
        "\n",
        "    \"\"\"if (\"request\" in topics) and (\"recommendation \" in topics):\n",
        "      previous_interactions=interactions\n",
        "      next_movie_to_watch=Predict_Movie([previous_interactions+' [MASK]'],big5=[Big5_personality],model=model_movie,tokenizer_m=tokenizer_4rec,device=device, batch_size=32)\n",
        "      print(next_movie_to_watch)\n",
        "      previous_interactions=previous_interactions+' '+next_movie_to_watch\"\"\"\n",
        "    previous_string=previous_string+' '+in_response+tokenizer_gpt.eos_token+ user_utterance + topics_user_utterance+tokenizer_gpt.eos_token+ '<recommender>'\n",
        "    new_user_input_ids = tokenizer_gpt.encode(previous_string ,return_tensors='pt').to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    if (('end' in topics_user_utterance) and (\"feedback\" in topics_user_utterance) and (\"no-topic\" in topics_user_utterance)):\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "interac=\" \".join(x for x in movie_history_watching)+previous_interactions+\"[MASK]\"\n",
        "per=[int(x) for x in users_personalities[0].split()]\n",
        "final_shot=Predict_Movie([interac],model=model_movie,tokenizer_m=tokenizer_4rec,device=device, batch_size=32)\n",
        "print(f\"DialoGPT: you may also like {movies_dict[final_shot]['name']} based on your previous watching history. Have a good one, be safe, bye.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBpJO_ggfGnI"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Beam search Decoding\n",
        "next_movie_to_watch=\"\"\n",
        "previous_string=persona_0+tokenizer_gpt.eos_token +'<recommender>'\n",
        "persona_ids=tokenizer_gpt.encode(previous_string , return_tensors='pt').to(device)\n",
        "new_user_input_ids=persona_ids\n",
        "previous_interactions=\"\"\n",
        "#print(f'previous string: {previous_string}')\n",
        "# Let's chat for 5 lines\n",
        "for step in range(100):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    # print(new_user_input_ids)\n",
        "    #chat_history_ids= tokenizer.encode(persona)\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = new_user_input_ids\n",
        "\n",
        "    #print(f\"bot_input_ids : {tokenizer_gpt.decode(bot_input_ids[0])}\")\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens, \n",
        "    chat_history_ids = model_gpt.dialogGPT.generate(\n",
        "        bot_input_ids, max_length=1000,\n",
        "        pad_token_id=tokenizer_gpt.eos_token_id,\n",
        "        no_repeat_ngram_size=5,\n",
        "        num_beams=5,\n",
        "        early_stop=True\n",
        "\n",
        "        \n",
        "    )\n",
        "    #print(f'chat history id : {tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0])}')\n",
        "\n",
        "#        do_sample=True,\n",
        "\n",
        "#num_return_sequences=3\n",
        "    \n",
        "    # pretty print last ouput tokens from bot\n",
        "    response=tokenizer_gpt.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "    #print(f'response oroginale ; {response}')\n",
        "\n",
        "\n",
        "    if \"<topic>\" in response:\n",
        "        in_response=response\n",
        "        response=response.split()\n",
        "        response=response[:response.index(\"<topic>\")]\n",
        "        response=\" \".join(x for x in response)\n",
        "    \n",
        "\n",
        "      \n",
        "    if '@' in response:\n",
        "      movie_pred=re.findall(r\"@[0-9]+\",response)[0]\n",
        "      previous_interactions=previous_interactions+' '+movie_pred\n",
        "\n",
        "\n",
        "    #print(f\"see all the dialogue {all_dialogue_text}\")\n",
        "    #print(f\"Fed input to the topic prediction {response}\")\n",
        "    _,topics=get_all_prediction([response],topic_list)\n",
        "    #_,topics=get_all_prediction_only_topic([topic_text_without_big5_personality],topic_list,intent_tokens)\n",
        "    #print(f\" predict the topic {topics}\")\n",
        "    \n",
        "    if '@' in response:\n",
        "      movie_pred=re.findall(r\"@[0-9]+\",response)[0]\n",
        "      #response=response+f\" you may also like {movies_dict[next_movie_to_watch]['name']} based on your previous history of watching.\"\n",
        "      print(\">>DialoGPT:      {}\".format(re.sub(movie_pred, \"\\x1b[6;30;42m\"+movies_dict[movie_pred]['name']+\"\\x1b[0m\", response)))\n",
        "    else:\n",
        "      print(\">>DialoGPT:      {}\".format(response))\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    user_utterance='<seeker> '+input(\">> User:         \")\n",
        "    _,topics_user_utterance=get_all_prediction([user_utterance],topic_list)\n",
        "    #print(f\"\\n User topic {topics_user_utterance}\\n\")\n",
        "    user_utterance=user_utterance\n",
        "\n",
        "    \"\"\"if (\"request\" in topics) and (\"recommendation \" in topics):\n",
        "      previous_interactions=interactions\n",
        "      next_movie_to_watch=Predict_Movie([previous_interactions+' [MASK]'],big5=[Big5_personality],model=model_movie,tokenizer_m=tokenizer_4rec,device=device, batch_size=32)\n",
        "      print(next_movie_to_watch)\n",
        "      previous_interactions=previous_interactions+' '+next_movie_to_watch\"\"\"\n",
        "    previous_string=previous_string+' '+in_response+tokenizer_gpt.eos_token+ user_utterance + topics_user_utterance+tokenizer_gpt.eos_token+ '<recommender>'\n",
        "    new_user_input_ids = tokenizer_gpt.encode(previous_string ,return_tensors='pt').to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    if (('end' in topics_user_utterance) and (\"feedback\" in topics_user_utterance) and (\"no-topic\" in topics_user_utterance)):\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "interac=\" \".join(x for x in movie_history_watching)+previous_interactions+\"[MASK]\"\n",
        "per=[int(x) for x in users_personalities[0].split()]\n",
        "final_shot=Predict_Movie([interac],model=model_movie,tokenizer_m=tokenizer_4rec,device=device, batch_size=32)\n",
        "print(f\"DialoGPT: you may also like {movies_dict[final_shot]['name']} based on your previous watching history. Have a good one, be safe, bye.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z08kN848fG-P"
      },
      "source": [
        "# with another personality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EM5hBwZufpKL",
        "outputId": "3c648b09-8cd0-47ea-cb04-6a5879f2c3b2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<big5> 28 79 21 50 60 </big5><|endoftext|><profile> i like to live on the ground .the place i want to travel most is india .i like kids .i like writing love letters very much .i like animation .i like sports .i like music very much .i really want to have sincere feelings .i think i am a loud voice .i like love very much </profile>'"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=5\n",
        "persona_0=test_rows[i][0]+tokenizer_gpt.eos_token+test_rows[i][1]\n",
        "conv_0=test_rows[i][2:]\n",
        "movie_history_watching=test_movie_history_watching[i]\n",
        "persona_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "l5HwryZ9fQB6",
        "outputId": "3b1e9bd0-d38c-4e60-d319-b5bd8b440f62"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<big5> 53 95 48 61 52 </big5><|endoftext|><profile> i like to live on the ground .the place i want to travel most is india .i like kids .i like writing love letters very much .i like animation .i like sports .i like music very much .i really want to have sincere feelings .i think i am a loud voice .i like love very much </profile>'"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=5\n",
        "persona_0=test_rows[45][0]+tokenizer_gpt.eos_token+test_rows[i][1]\n",
        "conv_0=test_rows[i][2:]\n",
        "movie_history_watching=test_movie_history_watching[i]\n",
        "persona_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZG-oa6ofehn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "IKoOd-dZfLm_",
        "outputId": "4e965bf5-e6c5-4f87-8e8b-e39655a0a427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>DialoGPT:      what are you doing?\n",
            ">> User:         i'm looking for a thriller movie, can you recommend me one, please\n",
            ">>DialoGPT:      then i highly recommend you to watch \u001b[6;30;42mcold blood\u001b[0m horror, which is a good movie, but i don't like it.\n",
            ">> User:         you know what i think i want to watch a comedy movie to laugh a little bit. do you have any recommendations\n",
            ">>DialoGPT:      then i recommend you to watch the \u001b[6;30;42mmummy\u001b[0m. this is a horror movie, but it is not a horror movie. it is a funny and funny movie. it is worth watching.\n",
            ">> User:         i love this movie, its a comedy and an adventure movie type, my best I will check it later . however, i would like to watch an inspirational movie for now\n",
            ">>DialoGPT:      then i recommend a thrilling and funny movie to you. have you ever watched \u001b[6;30;42mpeachy furious car\u001b[0m? this is a suspenseful and suspenseful comedy with a good plot and a good rhythm.\n",
            ">> User:         i think i changed my mind, is there any movie about suspense!\n",
            ">>DialoGPT:      then i highly recommend the \u001b[6;30;42mhorror\u001b[0m, a suspenseful thriller with a good rhythm and a good suspense film. conscience recommends you to watch it. suspense and horror are very important to the film. suspense is the source of horror movies in my heart, and it is also a very good suspense film, i recommend it to you!\n",
            ">> User:         thank you very much for your recommendation. i need to go now goodbye !\n",
            "DialoGPT: you may also like second mom based on your previous watching history. Have a good one, be safe, bye.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n>>DialoGPT:      what are you doing?\\n>> User:         i'm looking for a thriller movie, can you recommend me one, please.\\n>>DialoGPT:      i highly recommend the movie cold blood horror, which is a bit like a horror movie.\\n>> User:         you know what i think i want to watch a comedy movie to laugh a little bit. do you have any recommendations.\\n>>DialoGPT:      i recommend you to watch the mummy. this is a horror movie, but it is not a comedy. it is a good movie. it is worth watching.\\n>> User:          i love this movie, its a comedy and an adventure movie type, my best I will check it later . however, i would like to watch an inspirational movie for now\\n>>DialoGPT:      you can watch morning anchor, a relaxed and inspirational film, which is very suitable for you. it is a relaxing and inspirational film.\\n>> User:          i think i changed my mind, is there any movie about suspense!\\n>>DialoGPT:      i highly recommend picnic on the cliff, a suspenseful and suspenseful suspense film, which is very good. i watched it many times when i was a kid, and i still have a deep impression now. it's worth watching again. i recommend a suspenseful movie to you. you can watch it when you have time. you will definitely be satisfied.\\n>> User:         thank you very much for your recommendation. i need to go now goodbye !\\n\""
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#Beam search Decoding\n",
        "next_movie_to_watch=\"\"\n",
        "previous_string=persona_0+tokenizer_gpt.eos_token +'<recommender>'\n",
        "persona_ids=tokenizer_gpt.encode(previous_string , return_tensors='pt').to(device)\n",
        "new_user_input_ids=persona_ids\n",
        "previous_interactions=\"\"\n",
        "#print(f'previous string: {previous_string}')\n",
        "# Let's chat for 5 lines\n",
        "for step in range(100):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    # print(new_user_input_ids)\n",
        "    #chat_history_ids= tokenizer.encode(persona)\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = new_user_input_ids\n",
        "\n",
        "    #print(f\"bot_input_ids : {tokenizer_gpt.decode(bot_input_ids[0])}\")\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens, \n",
        "    chat_history_ids = model_gpt.dialogGPT.generate(\n",
        "        bot_input_ids, max_length=1000,\n",
        "        pad_token_id=tokenizer_gpt.eos_token_id,\n",
        "        no_repeat_ngram_size=5,\n",
        "        num_beams=5,\n",
        "        early_stop=True\n",
        "\n",
        "        \n",
        "    )\n",
        "    #print(f'chat history id : {tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0])}')\n",
        "\n",
        "#        do_sample=True,\n",
        "\n",
        "#num_return_sequences=3\n",
        "    \n",
        "    # pretty print last ouput tokens from bot\n",
        "    response=tokenizer_gpt.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "    #print(f'response oroginale ; {response}')\n",
        "\n",
        "\n",
        "    if \"<topic>\" in response:\n",
        "        in_response=response\n",
        "        response=response.split()\n",
        "        response=response[:response.index(\"<topic>\")]\n",
        "        response=\" \".join(x for x in response)\n",
        "    \n",
        "\n",
        "      \n",
        "    if '@' in response:\n",
        "      movie_pred=re.findall(r\"@[0-9]+\",response)[0]\n",
        "      previous_interactions=previous_interactions+' '+movie_pred\n",
        "\n",
        "\n",
        "    #print(f\"see all the dialogue {all_dialogue_text}\")\n",
        "    #print(f\"Fed input to the topic prediction {response}\")\n",
        "    _,topics=get_all_prediction([response],topic_list)\n",
        "    #_,topics=get_all_prediction_only_topic([topic_text_without_big5_personality],topic_list,intent_tokens)\n",
        "    #print(f\" predict the topic {topics}\")\n",
        "    \n",
        "    if '@' in response:\n",
        "      movie_pred=re.findall(r\"@[0-9]+\",response)[0]\n",
        "      #response=response+f\" you may also like {movies_dict[next_movie_to_watch]['name']} based on your previous history of watching.\"\n",
        "      print(\">>DialoGPT:      {}\".format(re.sub(movie_pred, \"\\x1b[6;30;42m\"+movies_dict[movie_pred]['name']+\"\\x1b[0m\", response)))\n",
        "    else:\n",
        "      print(\">>DialoGPT:      {}\".format(response))\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    user_utterance='<seeker> '+input(\">> User:         \")\n",
        "    _,topics_user_utterance=get_all_prediction([user_utterance],topic_list)\n",
        "    #print(f\"\\n User topic {topics_user_utterance}\\n\")\n",
        "    user_utterance=user_utterance\n",
        "\n",
        "    \"\"\"if (\"request\" in topics) and (\"recommendation \" in topics):\n",
        "      previous_interactions=interactions\n",
        "      next_movie_to_watch=Predict_Movie([previous_interactions+' [MASK]'],big5=[Big5_personality],model=model_movie,tokenizer_m=tokenizer_4rec,device=device, batch_size=32)\n",
        "      print(next_movie_to_watch)\n",
        "      previous_interactions=previous_interactions+' '+next_movie_to_watch\"\"\"\n",
        "    previous_string=previous_string+' '+in_response+tokenizer_gpt.eos_token+ user_utterance + topics_user_utterance+tokenizer_gpt.eos_token+ '<recommender>'\n",
        "    new_user_input_ids = tokenizer_gpt.encode(previous_string ,return_tensors='pt').to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    if (('end' in topics_user_utterance) and (\"feedback\" in topics_user_utterance) and (\"no-topic\" in topics_user_utterance)):\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "interac=\" \".join(x for x in movie_history_watching)+previous_interactions+\"[MASK]\"\n",
        "per=[int(x) for x in users_personalities[2].split()]\n",
        "final_shot=Predict_Movie([interac],model=model_movie,tokenizer_m=tokenizer_4rec,device=device, batch_size=32)\n",
        "print(f\"DialoGPT: you may also like {movies_dict[final_shot]['name']} based on your previous watching history. Have a good one, be safe, bye.\")\n",
        "\n",
        "\n",
        "#this user has a litle bit lower neurosisme factor EST, which makes him more relaxed person"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QqS0rr2FK9T"
      },
      "source": [
        "# Full dialog Scenario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "XWsDDVW_rxnQ",
        "outputId": "0e791ee4-8b66-44d7-ffad-3fb4efae057b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-87c94da1798b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Beam search Decoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnext_movie_to_watch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprevious_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersona_0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtokenizer_gpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'<recommender>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpersona_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer_gpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_string\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnew_user_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersona_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'persona_0' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "#Beam search Decoding\n",
        "next_movie_to_watch=\"\"\n",
        "previous_string=persona_0+tokenizer_gpt.eos_token +'<recommender>'\n",
        "persona_ids=tokenizer_gpt.encode(previous_string , return_tensors='pt').to(device)\n",
        "new_user_input_ids=persona_ids\n",
        "previous_interactions=\"\"\n",
        "#print(f'previous string: {previous_string}')\n",
        "# Let's chat for 5 lines\n",
        "for step in range(100):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    # print(new_user_input_ids)\n",
        "    #chat_history_ids= tokenizer.encode(persona)\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = new_user_input_ids\n",
        "\n",
        "    #print(f\"bot_input_ids : {tokenizer_gpt.decode(bot_input_ids[0])}\")\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens, \n",
        "    chat_history_ids = model_gpt.dialogGPT.generate(\n",
        "        bot_input_ids, max_length=1000,\n",
        "        pad_token_id=tokenizer_gpt.eos_token_id,\n",
        "        no_repeat_ngram_size=5,\n",
        "        num_beams=5,\n",
        "        early_stop=True\n",
        "\n",
        "        \n",
        "    )\n",
        "    #print(f'chat history id : {tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0])}')\n",
        "\n",
        "#        do_sample=True,\n",
        "\n",
        "#num_return_sequences=3\n",
        "    \n",
        "    # pretty print last ouput tokens from bot\n",
        "    response=tokenizer_gpt.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "    #print(f'response oroginale ; {response}')\n",
        "\n",
        "\n",
        "    if \"<topic>\" in response:\n",
        "        in_response=response\n",
        "        response=response.split()\n",
        "        response=response[:response.index(\"<topic>\")]\n",
        "        response=\" \".join(x for x in response)\n",
        "    \n",
        "\n",
        "      \n",
        "    if '@' in response:\n",
        "      movie_pred=re.findall(r\"@[0-9]+\",response)[0]\n",
        "      previous_interactions=previous_interactions+' '+movie_pred\n",
        "\n",
        "\n",
        "    #print(f\"see all the dialogue {all_dialogue_text}\")\n",
        "    #print(f\"Fed input to the topic prediction {response}\")\n",
        "    _,topics=get_all_prediction([response],topic_list)\n",
        "    #_,topics=get_all_prediction_only_topic([topic_text_without_big5_personality],topic_list,intent_tokens)\n",
        "    #print(f\" predict the topic {topics}\")\n",
        "    \n",
        "    if '@' in response:\n",
        "      movie_pred=re.findall(r\"@[0-9]+\",response)[0]\n",
        "      #response=response+f\" you may also like {movies_dict[next_movie_to_watch]['name']} based on your previous history of watching.\"\n",
        "      print(\">>DialoGPT:      {}\".format(re.sub(movie_pred, \"\\x1b[6;30;42m\"+movies_dict[movie_pred]['name']+\"\\x1b[0m\", response)))\n",
        "    else:\n",
        "      print(\">>DialoGPT:      {}\".format(response))\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    user_utterance='<seeker> '+input(\">> User:         \")\n",
        "    _,topics_user_utterance=get_all_prediction([user_utterance],topic_list)\n",
        "    #print(f\"\\n User topic {topics_user_utterance}\\n\")\n",
        "    user_utterance=user_utterance\n",
        "\n",
        "    \"\"\"if (\"request\" in topics) and (\"recommendation \" in topics):\n",
        "      previous_interactions=interactions\n",
        "      next_movie_to_watch=Predict_Movie([previous_interactions+' [MASK]'],big5=[Big5_personality],model=model_movie,tokenizer_m=tokenizer_4rec,device=device, batch_size=32)\n",
        "      print(next_movie_to_watch)\n",
        "      previous_interactions=previous_interactions+' '+next_movie_to_watch\"\"\"\n",
        "    previous_string=previous_string+' '+in_response+tokenizer_gpt.eos_token+ user_utterance + topics_user_utterance+tokenizer_gpt.eos_token+ '<recommender>'\n",
        "    new_user_input_ids = tokenizer_gpt.encode(previous_string ,return_tensors='pt').to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    if (('end' in topics_user_utterance) and (\"feedback\" in topics_user_utterance) and (\"no-topic\" in topics_user_utterance)):\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "interac=\" \".join(x for x in movie_history_watching)+previous_interactions+\"[MASK]\"\n",
        "per=[int(x) for x in users_personalities[0].split()]\n",
        "final_shot=Predict_Movie([interac],big5=[per],model=model_movie,tokenizer_m=tokenizer_4rec,device=device, batch_size=32)\n",
        "print(f\"DialoGPT: you may also like {movies_dict[final_shot]['name']} based on your previous watching history. Have a good one, be safe, bye.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Final CRS_CombineAll_Trained_Models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0131f67090dd407f86b3722c6ad77ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73d862abb92e4b46995b82502646c642",
              "IPY_MODEL_0bd189ca5431413e9b451ed16fcbe73f",
              "IPY_MODEL_a05d2632d3694b019880d9f3ab198c03"
            ],
            "layout": "IPY_MODEL_c0479d26477149df88290117cc225e78"
          }
        },
        "046bdea017104e1294a01d38690de20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a26c33a9fd7448cbc9f89a28756ac25",
              "IPY_MODEL_8682e6c77db143469b2e5e984f4b5989",
              "IPY_MODEL_5c85ad7fdf774e5d8364e0e864ee7b48"
            ],
            "layout": "IPY_MODEL_c8210b746b6943158128a419ee5a3e8a"
          }
        },
        "076ff170b97f42d481172e90ae4b45d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bd189ca5431413e9b451ed16fcbe73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1b31de53ab346a58a5a9cee889e1bd1",
            "max": 351265583,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6087e86a784c49c9992359bf12664b35",
            "value": 351265583
          }
        },
        "0d3a81420d9d41079e963833ddb0e65a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104a4160dc2f444db52b86df625ff176": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e32912cf22724b3897d9bef95511695a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78023d8db1b645c4be11952645290ccb",
            "value": 231508
          }
        },
        "11898f891ba6491891593fff42fb59ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11eef7965ce14ef3b5bd7952eaf74bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1351a203b4c24bf28d976fb0593bdcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17e1e7fba3a7455abb90540888fee672": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f496e7ab0148eb89c9dcf37674cf1d",
            "placeholder": "​",
            "style": "IPY_MODEL_f6c9a7dacd7048ddb5afa710cd2919b5",
            "value": " 226k/226k [00:00&lt;00:00, 301kB/s]"
          }
        },
        "1a00eb6e59104920b43ef550c1d0f2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "201e035152364c6a8ef83a74af664067": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "213350da35874dd39b218c8655d01c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e34a85c3aa254b3795e18bee7df76a6d",
              "IPY_MODEL_aaa0577cc3564419adc62805393c783b",
              "IPY_MODEL_2a9fe0d551664129b45923a59ca9a428"
            ],
            "layout": "IPY_MODEL_f45ab81220e74bf681b90549e56d67ca"
          }
        },
        "24df6c7c418c4e5e99d341d91e7f8f42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9fe0d551664129b45923a59ca9a428": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a05b82bd0234ec081a7675d30953700",
            "placeholder": "​",
            "style": "IPY_MODEL_201e035152364c6a8ef83a74af664067",
            "value": " 483/483 [00:00&lt;00:00, 20.1kB/s]"
          }
        },
        "30eee08690264b75b960ed18b57823f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a05b82bd0234ec081a7675d30953700": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e220e9c132d48be869cb9fbaa4f7c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f6bc0eba3941dc85dc206e1f19fbf3",
            "max": 641,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3d82f9c1a2e413e8bbd4ab3da4201c3",
            "value": 641
          }
        },
        "3ea79b701868421c90dc0e6b9e77e9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423f3cfe34a04827b15b6ff6f8e93ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46be53ad1a17403494f5bcdfc09de0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce40ce5a9cf48719d4728a8e3dc0445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dcf88109f20410f8962ad27c770e277": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50862acb7f164eca953b5cc8395f2978": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f6bc0eba3941dc85dc206e1f19fbf3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5828fdd0f15c49c3a63c7d7dac365d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b95a9f10409456faaca721bd2c838fe",
              "IPY_MODEL_d618ce88aea3422fb926c7529adde0dd",
              "IPY_MODEL_fb117ae4844a4b04bfb264eb38f2f85e"
            ],
            "layout": "IPY_MODEL_87ef5cf1954a4a78840c4d0223886593"
          }
        },
        "5a343b01af2e4c4682ab079718b5ebe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b611decc9f584cd7b49daa86e8fdadbf",
            "placeholder": "​",
            "style": "IPY_MODEL_1351a203b4c24bf28d976fb0593bdcbe",
            "value": "Downloading: 100%"
          }
        },
        "5b95a9f10409456faaca721bd2c838fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72fe2207b05943b294f016b8ef5ab523",
            "placeholder": "​",
            "style": "IPY_MODEL_f60391ad8abe4a7a8ac6720cc850fbe3",
            "value": "Downloading: 100%"
          }
        },
        "5c85ad7fdf774e5d8364e0e864ee7b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11eef7965ce14ef3b5bd7952eaf74bf6",
            "placeholder": "​",
            "style": "IPY_MODEL_774488e4911746b4a65bad69a6d2b201",
            "value": " 665/665 [00:00&lt;00:00, 21.2kB/s]"
          }
        },
        "60485b8c00ac46b1b9fdea39e32a5daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6087e86a784c49c9992359bf12664b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d98730ddfed4832b90a29b38e9071cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7227f9ffc0584bf9a690363409ef423c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72fe2207b05943b294f016b8ef5ab523": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73d862abb92e4b46995b82502646c642": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d98730ddfed4832b90a29b38e9071cd",
            "placeholder": "​",
            "style": "IPY_MODEL_bfbdb81a25b241c2bdc3d7d1d528e34e",
            "value": "Downloading: 100%"
          }
        },
        "73f240b501fd4bcb90d1149e6e27eefd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "774488e4911746b4a65bad69a6d2b201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78023d8db1b645c4be11952645290ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ed3e6ab3eac44ada0f5e74f1d7fcc9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8682e6c77db143469b2e5e984f4b5989": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73f240b501fd4bcb90d1149e6e27eefd",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8b9e2a334f146a4bb8f0148963beaff",
            "value": 665
          }
        },
        "87ef5cf1954a4a78840c4d0223886593": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a26c33a9fd7448cbc9f89a28756ac25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11898f891ba6491891593fff42fb59ff",
            "placeholder": "​",
            "style": "IPY_MODEL_1a00eb6e59104920b43ef550c1d0f2de",
            "value": "Downloading: 100%"
          }
        },
        "8f002d06ef96414581ae4a7a9b676567": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92571db359be40cba64c9dea3afb438d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93471d7f306b4eec8fb3904b7e86ce2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24df6c7c418c4e5e99d341d91e7f8f42",
            "placeholder": "​",
            "style": "IPY_MODEL_f39bc0eeaff949f5b7688664d3bf0245",
            "value": " 256M/256M [00:06&lt;00:00, 35.3MB/s]"
          }
        },
        "99ff89a794044a27832ee84052fde5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a343b01af2e4c4682ab079718b5ebe0",
              "IPY_MODEL_d4abc76ac26a4044bda1bf4a9a3c5a65",
              "IPY_MODEL_93471d7f306b4eec8fb3904b7e86ce2c"
            ],
            "layout": "IPY_MODEL_50862acb7f164eca953b5cc8395f2978"
          }
        },
        "9a07d78c0cf84663a574f1a42487c062": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c55a11ad21748f18571f159706b52b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46be53ad1a17403494f5bcdfc09de0f9",
            "placeholder": "​",
            "style": "IPY_MODEL_9a07d78c0cf84663a574f1a42487c062",
            "value": "Downloading: 100%"
          }
        },
        "9e3f1ae2d0a942068a80e564f57fae2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a05d2632d3694b019880d9f3ab198c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b56b32b1b291439abe98baa9ff823b1b",
            "placeholder": "​",
            "style": "IPY_MODEL_df4e9e0c679c4a8fbd5a997f9b92d215",
            "value": " 335M/335M [00:07&lt;00:00, 50.0MB/s]"
          }
        },
        "a73aa951444248cca267d1a55d0e4cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22e66afc7954f3d9bdeb2f0817d82ce",
            "placeholder": "​",
            "style": "IPY_MODEL_eace18d94c6c4adeab4d5560f4fb7963",
            "value": "Downloading: 100%"
          }
        },
        "a88d9bc4f9b140398c9a9d0a000c530e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaa0577cc3564419adc62805393c783b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ea79b701868421c90dc0e6b9e77e9f7",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e99ea3ccfd984d7488528f405f796f43",
            "value": 483
          }
        },
        "b020942d5ca4485da302432e1e4e6722": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b56b32b1b291439abe98baa9ff823b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b611decc9f584cd7b49daa86e8fdadbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7c3da56c93c4f488e8813fc95588d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f002d06ef96414581ae4a7a9b676567",
            "placeholder": "​",
            "style": "IPY_MODEL_b020942d5ca4485da302432e1e4e6722",
            "value": "Downloading: 100%"
          }
        },
        "b8c204a4641641a5b7f0e54c1c6473ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbdb81a25b241c2bdc3d7d1d528e34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0479d26477149df88290117cc225e78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d82f9c1a2e413e8bbd4ab3da4201c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8210b746b6943158128a419ee5a3e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b9e2a334f146a4bb8f0148963beaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cba24fcb0d6f4bf992260ad071f555ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1b31de53ab346a58a5a9cee889e1bd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d271eb29164a4703b1bac30f2ec74bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4abc76ac26a4044bda1bf4a9a3c5a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ce40ce5a9cf48719d4728a8e3dc0445",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e3f1ae2d0a942068a80e564f57fae2b",
            "value": 267967963
          }
        },
        "d5f496e7ab0148eb89c9dcf37674cf1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d618ce88aea3422fb926c7529adde0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92571db359be40cba64c9dea3afb438d",
            "max": 54245363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60485b8c00ac46b1b9fdea39e32a5daa",
            "value": 54245363
          }
        },
        "d6c2559efc8c4e988ba7b29e672ec8bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8af3cd6df849aaa51c87d4d9eca893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db8d122b53d3466cb792a6ebf72c876d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7227f9ffc0584bf9a690363409ef423c",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_423f3cfe34a04827b15b6ff6f8e93ffa",
            "value": 29
          }
        },
        "df4e9e0c679c4a8fbd5a997f9b92d215": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e22e66afc7954f3d9bdeb2f0817d82ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32912cf22724b3897d9bef95511695a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e34a85c3aa254b3795e18bee7df76a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30eee08690264b75b960ed18b57823f8",
            "placeholder": "​",
            "style": "IPY_MODEL_d271eb29164a4703b1bac30f2ec74bc2",
            "value": "Downloading: 100%"
          }
        },
        "e99ea3ccfd984d7488528f405f796f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eace18d94c6c4adeab4d5560f4fb7963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb5def54e83443708d42edec24128479": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c55a11ad21748f18571f159706b52b9",
              "IPY_MODEL_104a4160dc2f444db52b86df625ff176",
              "IPY_MODEL_17e1e7fba3a7455abb90540888fee672"
            ],
            "layout": "IPY_MODEL_7ed3e6ab3eac44ada0f5e74f1d7fcc9f"
          }
        },
        "f21de76db49a45e087a35880a61bb814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7c3da56c93c4f488e8813fc95588d6f",
              "IPY_MODEL_3e220e9c132d48be869cb9fbaa4f7c30",
              "IPY_MODEL_fe0f2e1b254d4073a8d3d8d091dcfc37"
            ],
            "layout": "IPY_MODEL_d6c2559efc8c4e988ba7b29e672ec8bd"
          }
        },
        "f39bc0eeaff949f5b7688664d3bf0245": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f45ab81220e74bf681b90549e56d67ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f60391ad8abe4a7a8ac6720cc850fbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6c9a7dacd7048ddb5afa710cd2919b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb117ae4844a4b04bfb264eb38f2f85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cba24fcb0d6f4bf992260ad071f555ad",
            "placeholder": "​",
            "style": "IPY_MODEL_a88d9bc4f9b140398c9a9d0a000c530e",
            "value": " 51.7M/51.7M [00:01&lt;00:00, 50.0MB/s]"
          }
        },
        "fcee081f09114b829c88090c216886a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8c204a4641641a5b7f0e54c1c6473ac",
            "placeholder": "​",
            "style": "IPY_MODEL_db8af3cd6df849aaa51c87d4d9eca893",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.23kB/s]"
          }
        },
        "fe0f2e1b254d4073a8d3d8d091dcfc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d3a81420d9d41079e963833ddb0e65a",
            "placeholder": "​",
            "style": "IPY_MODEL_076ff170b97f42d481172e90ae4b45d9",
            "value": " 641/641 [00:00&lt;00:00, 24.4kB/s]"
          }
        },
        "fe576e433c4d4d788c86d4f6c6838788": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a73aa951444248cca267d1a55d0e4cf1",
              "IPY_MODEL_db8d122b53d3466cb792a6ebf72c876d",
              "IPY_MODEL_fcee081f09114b829c88090c216886a8"
            ],
            "layout": "IPY_MODEL_4dcf88109f20410f8962ad27c770e277"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}