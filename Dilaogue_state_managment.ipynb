{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dilaogue_state_managment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad77cd4021ce4efa95626beb3f682c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffc0d28c63384e56bc5430232e5d4573",
              "IPY_MODEL_e7920dc1dca449589a8e514fa17efa60",
              "IPY_MODEL_90de2b73693a46a5945f08e354b9c7e4"
            ],
            "layout": "IPY_MODEL_a465c58fb8ca40f4a22b337b37d3f8ce"
          }
        },
        "ffc0d28c63384e56bc5430232e5d4573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2eca588409d47c599ad0ecae45fa963",
            "placeholder": "​",
            "style": "IPY_MODEL_cdfd3038cee64fafa2500bf18ed66b71",
            "value": "Downloading: 100%"
          }
        },
        "e7920dc1dca449589a8e514fa17efa60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebf2938ee65a4a0e9bdbdb7e4a99220b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd3b52db836542b5bc513e8928d31c58",
            "value": 231508
          }
        },
        "90de2b73693a46a5945f08e354b9c7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_745eb312ccc441a3926ffdc774eb4022",
            "placeholder": "​",
            "style": "IPY_MODEL_3d9b9d33e1ed408fbb0cef9a86496665",
            "value": " 226k/226k [00:00&lt;00:00, 2.48MB/s]"
          }
        },
        "a465c58fb8ca40f4a22b337b37d3f8ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2eca588409d47c599ad0ecae45fa963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdfd3038cee64fafa2500bf18ed66b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebf2938ee65a4a0e9bdbdb7e4a99220b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3b52db836542b5bc513e8928d31c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "745eb312ccc441a3926ffdc774eb4022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9b9d33e1ed408fbb0cef9a86496665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a70c2f4123e944559b84ea5dc80aeaad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b494b5bd1c7e44b68b463832d808acae",
              "IPY_MODEL_ec11e3c997e54c86a4278c8e7afc4fcc",
              "IPY_MODEL_2340e71b3c4a4259b9165daec92ac100"
            ],
            "layout": "IPY_MODEL_cbc1d3e713c548fdb4c1652c4f7ae762"
          }
        },
        "b494b5bd1c7e44b68b463832d808acae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_555c8c05f7b141b4b90d4a65468517ee",
            "placeholder": "​",
            "style": "IPY_MODEL_5798a0c8a1c34b9589fcc291271597bf",
            "value": "Downloading: 100%"
          }
        },
        "ec11e3c997e54c86a4278c8e7afc4fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b2d60a4ea124e389eefd0d35326d4a5",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be02606c8fb64ebb81d09d7039d8a28f",
            "value": 29
          }
        },
        "2340e71b3c4a4259b9165daec92ac100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83fba4ee815e4ac6ba8ee7790e7ef49c",
            "placeholder": "​",
            "style": "IPY_MODEL_384f5468d0bc44bb9d09c13ece8ad0ea",
            "value": " 29.0/29.0 [00:00&lt;00:00, 888B/s]"
          }
        },
        "cbc1d3e713c548fdb4c1652c4f7ae762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "555c8c05f7b141b4b90d4a65468517ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5798a0c8a1c34b9589fcc291271597bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b2d60a4ea124e389eefd0d35326d4a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be02606c8fb64ebb81d09d7039d8a28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83fba4ee815e4ac6ba8ee7790e7ef49c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "384f5468d0bc44bb9d09c13ece8ad0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21b76f9552194b1493aa87e427bd08b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7037db0ed3b4d2a8edf1140855466a8",
              "IPY_MODEL_938b3f39e2c54fe1af0374b28aef3033",
              "IPY_MODEL_ec00b313c2d34724b5f23083aefe2b61"
            ],
            "layout": "IPY_MODEL_1515dbbd1d89401ba689e72d9cfdcde3"
          }
        },
        "d7037db0ed3b4d2a8edf1140855466a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc534815428e4e5eb8eea6e12a76945d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d896ce3394c45779d13a14b97c9f27a",
            "value": "Downloading: 100%"
          }
        },
        "938b3f39e2c54fe1af0374b28aef3033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e48c70794ff24c55935193813d3c0b9a",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d426fced7c884e86969fc69edabd8b28",
            "value": 665
          }
        },
        "ec00b313c2d34724b5f23083aefe2b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fbf4a138fdd4c4a9b1000ecb4a758c5",
            "placeholder": "​",
            "style": "IPY_MODEL_cbeed0b40d7a4d9b999042cc191d588b",
            "value": " 665/665 [00:00&lt;00:00, 21.4kB/s]"
          }
        },
        "1515dbbd1d89401ba689e72d9cfdcde3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc534815428e4e5eb8eea6e12a76945d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d896ce3394c45779d13a14b97c9f27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e48c70794ff24c55935193813d3c0b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d426fced7c884e86969fc69edabd8b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fbf4a138fdd4c4a9b1000ecb4a758c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbeed0b40d7a4d9b999042cc191d588b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f8b1fd5c6304acd96ec9e1983dd1caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b311affbe3e4a9db538d27809adda37",
              "IPY_MODEL_a2549169058448278e34c1b0e4043b12",
              "IPY_MODEL_4a9ce97c4321438298c089e764b69252"
            ],
            "layout": "IPY_MODEL_17e81f41e26e406d93e45182ccf98f1d"
          }
        },
        "2b311affbe3e4a9db538d27809adda37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3645d246fa234a08a6d7a28d1d0253ab",
            "placeholder": "​",
            "style": "IPY_MODEL_93d9d12a8a1a4830ac73163328d3306e",
            "value": "Downloading: 100%"
          }
        },
        "a2549169058448278e34c1b0e4043b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d3f82ecd45a46b1aa4499c5361487d4",
            "max": 54245363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c521bc874a949caba4543e6682c04fe",
            "value": 54245363
          }
        },
        "4a9ce97c4321438298c089e764b69252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_559bb867d114437d972146d8631998c6",
            "placeholder": "​",
            "style": "IPY_MODEL_8e58af26c414458e9a1da91aade05c31",
            "value": " 51.7M/51.7M [00:01&lt;00:00, 57.6MB/s]"
          }
        },
        "17e81f41e26e406d93e45182ccf98f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3645d246fa234a08a6d7a28d1d0253ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d9d12a8a1a4830ac73163328d3306e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d3f82ecd45a46b1aa4499c5361487d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c521bc874a949caba4543e6682c04fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "559bb867d114437d972146d8631998c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e58af26c414458e9a1da91aade05c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSDezoagD0rG",
        "outputId": "37733d75-0b87-4299-d9ed-abe3da7e06ba"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws9y5SKK151x",
        "outputId": "631c4a17-ecf1-4121-975c-4d1be51e3ff3"
      },
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install transformers\n",
        "!pip install dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.63.0)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[K     |████████████████████████████████| 398 kB 66.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Collecting typing-extensions>=4.0.0\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 75.4 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.7)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.44.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 56.3 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 74.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: typing-extensions, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, PyYAML, pytorch-lightning\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.0 torchmetrics-0.7.3 typing-extensions-4.1.1 yarl-1.7.2\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n",
            "Collecting dataset\n",
            "  Downloading dataset-1.5.2-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from dataset) (1.4.32)\n",
            "Collecting banal>=1.0.1\n",
            "  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
            "Collecting alembic>=0.6.2\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (4.11.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.2->dataset) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.0.1)\n",
            "Installing collected packages: Mako, banal, alembic, dataset\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 banal-1.0.6 dataset-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize=10\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import BCEWithLogitsLoss,MSELoss,BCELoss\n",
        "from transformers import AdamW, ElectraTokenizer, ElectraModel, ElectraConfig\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "rNtZktGO_2ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLyBD00g6Rib"
      },
      "outputs": [],
      "source": [
        "#Define the computation ressources\n",
        "device =torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJoOCSPSDqC5"
      },
      "source": [
        "import pickle\n",
        "with open('./drive/MyDrive/Data/English_TGD2_TGD_All_data.pkl','rb') as file:\n",
        "    TGD_All_data=pickle.load(file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bym3_tybI3M"
      },
      "source": [
        "# Remove the movie tokens from the topic field as they do not help for predicting the topic of the utterance\n",
        "def remove_movie_from_path_goal(TGD_All_data,typee='train'):\n",
        "  for i, dial in enumerate(TGD_All_data[typee]):\n",
        "    goal_path=dial['goal_path']\n",
        "    for k, v in goal_path.items():\n",
        "      v=[x for x in v if x[0]!='@']\n",
        "      goal_path[k]=v\n",
        "    \n",
        "    TGD_All_data[typee][i]['goal_path']=goal_path\n",
        "  return TGD_All_data[typee]\n",
        "\n",
        "TGD_All_data['train']=remove_movie_from_path_goal(TGD_All_data,typee='train')\n",
        "TGD_All_data['test']=remove_movie_from_path_goal(TGD_All_data,typee='test')\n",
        "TGD_All_data['valid']=remove_movie_from_path_goal(TGD_All_data,typee='valid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzQYBqycsSMv"
      },
      "source": [
        "# reformulate our data by combining both intent and topics topics\n",
        "def create_entent_topic(TGD_All_data=TGD_All_data,typee=\"train\"):\n",
        "\n",
        "  topic_list=TGD_All_data[\"real_topics\"].values()\n",
        "  for i,dial in enumerate(TGD_All_data[typee]):\n",
        "    goal_path=dial[\"goal_path\"]\n",
        "    new_goal_path={}\n",
        "    \n",
        "    for k,v in goal_path.items():\n",
        "      topics=[x for x in v if x in topic_list]\n",
        "      intents=[x for x in v if x not in topic_list]\n",
        "      if(len(topics)==0):\n",
        "        topics=[\"no-topic\"]\n",
        "      new_goal_path[k]={\"topics\":intents+topics}\n",
        "    TGD_All_data[typee][i][\"goal_path\"]=new_goal_path\n",
        "\n",
        "  return TGD_All_data\n",
        "TGD_All_data=create_entent_topic(TGD_All_data=TGD_All_data,typee=\"train\")\n",
        "TGD_All_data=create_entent_topic(TGD_All_data=TGD_All_data,typee=\"test\")\n",
        "TGD_All_data=create_entent_topic(TGD_All_data=TGD_All_data,typee=\"valid\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDk31jKMWEhv"
      },
      "source": [
        "# Create our training data where we combine each utterance with the previous ones and the previous topics.\n",
        "# the current topic is defined as a label for the new formulated row\n",
        "import re\n",
        "def create_path_included_data(TGD_All_data,typee='valid'):\n",
        "  data_dialogue_rows=[]\n",
        "  data_dialogue_labels=[]\n",
        "  for i,dial in enumerate(TGD_All_data[typee]):\n",
        "    goal_path=dial['goal_path']\n",
        "    messages=dial['messages']\n",
        "\n",
        "    line=' '\n",
        "    for i,v in enumerate(messages):\n",
        "\n",
        "      m='<'+v['role'].lower()+'>'+' '+v['content']\n",
        "      label=' '.join(x for x in goal_path[v['local_id']][\"topics\"])\n",
        "      \n",
        "      \n",
        "      m=re.sub(' +', ' ', m)\n",
        "      line=line+m\n",
        "    \n",
        "      line=re.sub(' +', ' ', line).strip()\n",
        "      data_dialogue_labels.append(label)\n",
        "      data_dialogue_rows.append(line)\n",
        "      line=line+' <topic> '+ label +\" </topic> \"\n",
        "    \n",
        "  return data_dialogue_rows,data_dialogue_labels\n",
        "    \n",
        "\n",
        "train_rows,train_labels=create_path_included_data(TGD_All_data,typee='train')   \n",
        "test_rows,test_labels=create_path_included_data(TGD_All_data,typee='test')   \n",
        "valid_rows,valid_labels=create_path_included_data(TGD_All_data,typee='valid')   \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp8K5od91VJF"
      },
      "outputs": [],
      "source": [
        "# Mask the movie tokens from the utterance to help the model predicting the topic of the utterance independently from the mentioned movie\n",
        "\n",
        "def add_movie_mask( train_rows):\n",
        "  t=[]\n",
        "  for m in train_rows:\n",
        "    if(\"@\" in m ):\n",
        "        lin= np.array([word for word in m.split(\" \") ])\n",
        "        indexes=[i for i,v in enumerate(lin) if v[0]==\"@\"]\n",
        "        lin[indexes]=\"[Movie]\" \n",
        "        m=\" \".join(p for p in lin)\n",
        "        m=re.sub(' +', ' ', m).strip()\n",
        "    t.append(m)\n",
        "  return t\n",
        "train_rows=add_movie_mask( train_rows)\n",
        "test_rows=add_movie_mask( test_rows)\n",
        "valid_rows=add_movie_mask( valid_rows)\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#an example of the training rows\n",
        "train_rows[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGH_pWmx03iZ",
        "outputId": "df421712-eb0f-46ce-d2a6-53605f87145b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<recommender> how are things',\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ?\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ?\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom . <topic> recommended movies no-topic </topic> <seeker> this movie is really good . it turns out that you liked little mice in your childhood . when i was a child , i only thought that mice were too cunning , and i always thought how cute a tiger was . sure enough , everyone’s childhood is different , haha .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom . <topic> recommended movies no-topic </topic> <seeker> this movie is really good . it turns out that you liked little mice in your childhood . when i was a child , i only thought that mice were too cunning , and i always thought how cute a tiger was . sure enough , everyone’s childhood is different , haha . <topic> feedback talk childhood </topic> <recommender> when i was a child , i not only liked little mouse , but also other favorite animations . i recommend them to you .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom . <topic> recommended movies no-topic </topic> <seeker> this movie is really good . it turns out that you liked little mice in your childhood . when i was a child , i only thought that mice were too cunning , and i always thought how cute a tiger was . sure enough , everyone’s childhood is different , haha . <topic> feedback talk childhood </topic> <recommender> when i was a child , i not only liked little mouse , but also other favorite animations . i recommend them to you . <topic> request recommendation childhood </topic> <seeker> well , the bigger you are , the more you like to watch childhood movies when you were a kid . recommend a movie full of childhood memories !\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom . <topic> recommended movies no-topic </topic> <seeker> this movie is really good . it turns out that you liked little mice in your childhood . when i was a child , i only thought that mice were too cunning , and i always thought how cute a tiger was . sure enough , everyone’s childhood is different , haha . <topic> feedback talk childhood </topic> <recommender> when i was a child , i not only liked little mouse , but also other favorite animations . i recommend them to you . <topic> request recommendation childhood </topic> <seeker> well , the bigger you are , the more you like to watch childhood movies when you were a kid . recommend a movie full of childhood memories ! <topic> allow recommendations recall childhood </topic> <recommender> you will like [Movie] . when i was a kid , i thought that goats could not be so smart , but this film made me think that goats are still very witty .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom . <topic> recommended movies no-topic </topic> <seeker> this movie is really good . it turns out that you liked little mice in your childhood . when i was a child , i only thought that mice were too cunning , and i always thought how cute a tiger was . sure enough , everyone’s childhood is different , haha . <topic> feedback talk childhood </topic> <recommender> when i was a child , i not only liked little mouse , but also other favorite animations . i recommend them to you . <topic> request recommendation childhood </topic> <seeker> well , the bigger you are , the more you like to watch childhood movies when you were a kid . recommend a movie full of childhood memories ! <topic> allow recommendations recall childhood </topic> <recommender> you will like [Movie] . when i was a kid , i thought that goats could not be so smart , but this film made me think that goats are still very witty . <topic> recommended movies no-topic </topic> <seeker> well , this video is really good . if you haven't watched this video , it only means that you don't have a childhood . the little dolls now must also like this movie very much .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom . <topic> recommended movies no-topic </topic> <seeker> this movie is really good . it turns out that you liked little mice in your childhood . when i was a child , i only thought that mice were too cunning , and i always thought how cute a tiger was . sure enough , everyone’s childhood is different , haha . <topic> feedback talk childhood </topic> <recommender> when i was a child , i not only liked little mouse , but also other favorite animations . i recommend them to you . <topic> request recommendation childhood </topic> <seeker> well , the bigger you are , the more you like to watch childhood movies when you were a kid . recommend a movie full of childhood memories ! <topic> allow recommendations recall childhood </topic> <recommender> you will like [Movie] . when i was a kid , i thought that goats could not be so smart , but this film made me think that goats are still very witty . <topic> recommended movies no-topic </topic> <seeker> well , this video is really good . if you haven't watched this video , it only means that you don't have a childhood . the little dolls now must also like this movie very much . <topic> feedback talk baby </topic> <recommender> yes , the good looking classic animation is full of memories .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom . <topic> recommended movies no-topic </topic> <seeker> this movie is really good . it turns out that you liked little mice in your childhood . when i was a child , i only thought that mice were too cunning , and i always thought how cute a tiger was . sure enough , everyone’s childhood is different , haha . <topic> feedback talk childhood </topic> <recommender> when i was a child , i not only liked little mouse , but also other favorite animations . i recommend them to you . <topic> request recommendation childhood </topic> <seeker> well , the bigger you are , the more you like to watch childhood movies when you were a kid . recommend a movie full of childhood memories ! <topic> allow recommendations recall childhood </topic> <recommender> you will like [Movie] . when i was a kid , i thought that goats could not be so smart , but this film made me think that goats are still very witty . <topic> recommended movies no-topic </topic> <seeker> well , this video is really good . if you haven't watched this video , it only means that you don't have a childhood . the little dolls now must also like this movie very much . <topic> feedback talk baby </topic> <recommender> yes , the good looking classic animation is full of memories . <topic> talk recall </topic> <seeker> are there any good movies in your childhood worth remembering ?\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom . <topic> recommended movies no-topic </topic> <seeker> this movie is really good . it turns out that you liked little mice in your childhood . when i was a child , i only thought that mice were too cunning , and i always thought how cute a tiger was . sure enough , everyone’s childhood is different , haha . <topic> feedback talk childhood </topic> <recommender> when i was a child , i not only liked little mouse , but also other favorite animations . i recommend them to you . <topic> request recommendation childhood </topic> <seeker> well , the bigger you are , the more you like to watch childhood movies when you were a kid . recommend a movie full of childhood memories ! <topic> allow recommendations recall childhood </topic> <recommender> you will like [Movie] . when i was a kid , i thought that goats could not be so smart , but this film made me think that goats are still very witty . <topic> recommended movies no-topic </topic> <seeker> well , this video is really good . if you haven't watched this video , it only means that you don't have a childhood . the little dolls now must also like this movie very much . <topic> feedback talk baby </topic> <recommender> yes , the good looking classic animation is full of memories . <topic> talk recall </topic> <seeker> are there any good movies in your childhood worth remembering ? <topic> request recommendation recall </topic> <recommender> i recommend [Movie] . this is an animated cartoon that i have watched many times without getting tired of it . it is an educational cartoon .\",\n",
              " \"<recommender> how are things <topic> start conversation no-topic </topic> <seeker> it's okay recently , still alone , struggling in shanghai , checking in every day , nothing else . how are you ? <topic> talk struggle </topic> <recommender> i've been doing well recently , and the local tyrant will receive it next week , which is the company's reward . <topic> talk award </topic> <seeker> it's really outstanding ! i don't care much about rewards , so i won't mention rewards . let's work hard and earnestly , and be a good kid who is hardworking and motivated . <topic> refuse talk award child </topic> <recommender> indeed , work attitude is the most important thing . this reminds me a lot of things when i first entered society . <topic> talk recall </topic> <seeker> speaking of which , do you recommend any movies worth remembering ? <topic> request recommendation recall </topic> <recommender> how about [Movie] , a classic childhood memory film , an adventure with courage and wisdom . <topic> recommended movies no-topic </topic> <seeker> this movie is really good . it turns out that you liked little mice in your childhood . when i was a child , i only thought that mice were too cunning , and i always thought how cute a tiger was . sure enough , everyone’s childhood is different , haha . <topic> feedback talk childhood </topic> <recommender> when i was a child , i not only liked little mouse , but also other favorite animations . i recommend them to you . <topic> request recommendation childhood </topic> <seeker> well , the bigger you are , the more you like to watch childhood movies when you were a kid . recommend a movie full of childhood memories ! <topic> allow recommendations recall childhood </topic> <recommender> you will like [Movie] . when i was a kid , i thought that goats could not be so smart , but this film made me think that goats are still very witty . <topic> recommended movies no-topic </topic> <seeker> well , this video is really good . if you haven't watched this video , it only means that you don't have a childhood . the little dolls now must also like this movie very much . <topic> feedback talk baby </topic> <recommender> yes , the good looking classic animation is full of memories . <topic> talk recall </topic> <seeker> are there any good movies in your childhood worth remembering ? <topic> request recommendation recall </topic> <recommender> i recommend [Movie] . this is an animated cartoon that i have watched many times without getting tired of it . it is an educational cartoon . <topic> recommended movies no-topic </topic> <seeker> well , it is indeed a typical domestic animation , these animations full of childhood memories , i feel great , thank you , goodbye !\",\n",
              " '<recommender> what are you busy with ?',\n",
              " '<recommender> what are you busy with ? <topic> start conversation no-topic </topic> <seeker> i am taking my children to read a textbook about the knowledge of the earth . the world is so big that there are no exceptions .',\n",
              " \"<recommender> what are you busy with ? <topic> start conversation no-topic </topic> <seeker> i am taking my children to read a textbook about the knowledge of the earth . the world is so big that there are no exceptions . <topic> talk earth </topic> <recommender> well , it's good to read the textbook , which is an eye opener for children .\",\n",
              " \"<recommender> what are you busy with ? <topic> start conversation no-topic </topic> <seeker> i am taking my children to read a textbook about the knowledge of the earth . the world is so big that there are no exceptions . <topic> talk earth </topic> <recommender> well , it's good to read the textbook , which is an eye opener for children . <topic> talk textbook </topic> <seeker> yes , although children like reading books most , they prefer to watch animation . can you recommend an animation movie for me ?\"]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKNXEGiZiEGz"
      },
      "source": [
        "#get the unique topic tokens so that we can add them to the vocabulary of the pre-trained model\n",
        "topic_tokens=[]\n",
        "for i,dial in enumerate(TGD_All_data[\"train\"]):\n",
        "    goal_path=dial[\"goal_path\"]    \n",
        "    for k,v in goal_path.items():\n",
        "      \n",
        "      topic_tokens=topic_tokens+[x for x in v[\"topics\"]]\n",
        "topic_tokens=np.unique(topic_tokens)\n",
        "topic_list=list(TGD_All_data['real_topics'].values())\n",
        "topic_list=list(np.unique(topic_list+list(topic_tokens)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the pre-trained electra tokenizer small version\n",
        "model_name=\"google/electra-small-discriminator\"\n",
        "\n",
        "tokenizer_4rec = ElectraTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ad77cd4021ce4efa95626beb3f682c84",
            "ffc0d28c63384e56bc5430232e5d4573",
            "e7920dc1dca449589a8e514fa17efa60",
            "90de2b73693a46a5945f08e354b9c7e4",
            "a465c58fb8ca40f4a22b337b37d3f8ce",
            "e2eca588409d47c599ad0ecae45fa963",
            "cdfd3038cee64fafa2500bf18ed66b71",
            "ebf2938ee65a4a0e9bdbdb7e4a99220b",
            "bd3b52db836542b5bc513e8928d31c58",
            "745eb312ccc441a3926ffdc774eb4022",
            "3d9b9d33e1ed408fbb0cef9a86496665",
            "a70c2f4123e944559b84ea5dc80aeaad",
            "b494b5bd1c7e44b68b463832d808acae",
            "ec11e3c997e54c86a4278c8e7afc4fcc",
            "2340e71b3c4a4259b9165daec92ac100",
            "cbc1d3e713c548fdb4c1652c4f7ae762",
            "555c8c05f7b141b4b90d4a65468517ee",
            "5798a0c8a1c34b9589fcc291271597bf",
            "6b2d60a4ea124e389eefd0d35326d4a5",
            "be02606c8fb64ebb81d09d7039d8a28f",
            "83fba4ee815e4ac6ba8ee7790e7ef49c",
            "384f5468d0bc44bb9d09c13ece8ad0ea",
            "21b76f9552194b1493aa87e427bd08b6",
            "d7037db0ed3b4d2a8edf1140855466a8",
            "938b3f39e2c54fe1af0374b28aef3033",
            "ec00b313c2d34724b5f23083aefe2b61",
            "1515dbbd1d89401ba689e72d9cfdcde3",
            "bc534815428e4e5eb8eea6e12a76945d",
            "0d896ce3394c45779d13a14b97c9f27a",
            "e48c70794ff24c55935193813d3c0b9a",
            "d426fced7c884e86969fc69edabd8b28",
            "5fbf4a138fdd4c4a9b1000ecb4a758c5",
            "cbeed0b40d7a4d9b999042cc191d588b"
          ]
        },
        "id": "hNNVJnrwCm0K",
        "outputId": "dfa5367e-e2ec-4443-f6a6-6303fde88c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad77cd4021ce4efa95626beb3f682c84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a70c2f4123e944559b84ea5dc80aeaad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21b76f9552194b1493aa87e427bd08b6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9voAYyEH6Gcy"
      },
      "outputs": [],
      "source": [
        "#define our data subsets \n",
        "train_data=train_rows\n",
        "test_data=test_rows\n",
        "valid_data=valid_rows"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform the topic list into list of words\n",
        "topic_list=\" \".join(x for x in topic_list)\n",
        "topic_list=list(np.unique(topic_list.split())) "
      ],
      "metadata": {
        "id": "tc9WgcZz4en6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6O8Bv8k5bM8"
      },
      "source": [
        "#verify the list of tokens that does not exist in the pre-trained model vocabulary so that we can add them\n",
        "topics_not_existed=[x for x in topic_list if x not in tokenizer_4rec.get_vocab().keys() ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdgDUwq7ke1O"
      },
      "source": [
        "#Define the special tokens that we are gonna add to the utterances\n",
        "\n",
        "special_tokens=['<entent>','</entent>','<recommender>','<topic>',\"</topic>\",'<seeker>',\"no-topic\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJyY3WmH3zpr"
      },
      "source": [
        "#Define the words that we are gonna add to the pre-trained model vocabulary\n",
        "vocab_to_add=topics_not_existed+special_tokens+['uk']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCljV99fm_x_"
      },
      "source": [
        "#Create one-hot vector representation for the labels\n",
        "def get_train_label_vector(train_labels, vocab_topics):\n",
        "\n",
        "  topic_labels_vector=[]\n",
        "\n",
        "  list_labels=[]\n",
        "  \n",
        "  for i, topic in enumerate(train_labels): \n",
        "    label_topic=np.zeros(len(vocab_topics))\n",
        "    for j,t in enumerate(topic.split()): \n",
        "        \n",
        "        label_topic[vocab_topics.index(t)]=1\n",
        "\n",
        "    topic_labels_vector.append(label_topic)\n",
        "\n",
        " \n",
        "  return topic_labels_vector\n",
        "  \n",
        "train_labels_vector=get_train_label_vector(train_labels, topic_list)\n",
        "test_labels_vector=get_train_label_vector(test_labels, topic_list)\n",
        "valid_labels_vector=get_train_label_vector(valid_labels, topic_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsEtaWzhdlLL"
      },
      "source": [
        "#Rename the features and labels subsets\n",
        "X_train, y_train_topic_vector =train_rows,train_labels_vector\n",
        "X_test, y_test_topic_vector =test_rows,test_labels_vector\n",
        "X_valid, y_valid_topic_vector =valid_rows,valid_labels_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2we-aun2G_MG"
      },
      "source": [
        "#Design the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQLj3h_y6uEq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "6f8b1fd5c6304acd96ec9e1983dd1caf",
            "2b311affbe3e4a9db538d27809adda37",
            "a2549169058448278e34c1b0e4043b12",
            "4a9ce97c4321438298c089e764b69252",
            "17e81f41e26e406d93e45182ccf98f1d",
            "3645d246fa234a08a6d7a28d1d0253ab",
            "93d9d12a8a1a4830ac73163328d3306e",
            "0d3f82ecd45a46b1aa4499c5361487d4",
            "7c521bc874a949caba4543e6682c04fe",
            "559bb867d114437d972146d8631998c6",
            "8e58af26c414458e9a1da91aade05c31"
          ]
        },
        "id": "YmCZ94t4XqM2",
        "outputId": "c2740740-233b-45f8-a322-3e28a82efe23"
      },
      "source": [
        "#Instentiate the pre-trained electra model\n",
        "pre_tained_model=ElectraModel.from_pretrained('google/electra-small-discriminator')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/51.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f8b1fd5c6304acd96ec9e1983dd1caf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kvQP09Oz7Az",
        "outputId": "93527254-dad7-43a1-a403-70215dec4ab5"
      },
      "source": [
        "tokenizer_4rec.add_tokens(vocab_to_add) # add the pre-defined vocab to add to the electra tokenizer and pre-trained model\n",
        "pre_tained_model.resize_token_embeddings(len(tokenizer_4rec)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(31238, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEoxOnfBRBtW"
      },
      "source": [
        "# rename our sub sets \n",
        "train_data= X_train\n",
        "test_data = X_test\n",
        "valid_data = X_valid\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTpWTB5kShO-"
      },
      "source": [
        "#Define a tokenization function using the pre-trained tokenizer model version\n",
        "def tokenize_inputs(liste, tokenizer, num_embeddings=512):\n",
        "    \n",
        "    outputs = tokenizer.batch_encode_plus(liste,truncation=True,return_tensors='pt',return_attention_mask=True,max_length=512, padding='max_length')\n",
        "    # convert tokenized text into numeric ids for the appropriate LM\n",
        "    input_ids =outputs.input_ids\n",
        "    \n",
        "\n",
        "    return (input_ids,outputs.attention_mask)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fEQLMpiTTbf"
      },
      "source": [
        "#Tokenize train, test, and validation subsets\n",
        "train_input_ids,train_attention_masks=tokenize_inputs(train_data, tokenizer_4rec, num_embeddings=512) #1024\n",
        "valid_input_ids,valid_attention_masks=tokenize_inputs(valid_data, tokenizer_4rec, num_embeddings=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_ids,test_attention_masks=tokenize_inputs(test_data, tokenizer_4rec, num_embeddings=512)\n"
      ],
      "metadata": {
        "id": "ft8IDUpDKvfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOnTMNVvuTuW"
      },
      "source": [
        "#rename our data names\n",
        "X_train,train_masks,Y_train_topic= (train_input_ids,train_attention_masks,torch.tensor(np.array(y_train_topic_vector),dtype=torch.float32))\n",
        "\n",
        "X_valid,valid_masks,Y_valid_topic= (valid_input_ids,valid_attention_masks,torch.tensor(np.array(y_valid_topic_vector),dtype=torch.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAJmRw-QVDdH"
      },
      "source": [
        "#Make the data convininet to be used by the model in the pytprch framework\n",
        "\n",
        "train_data = TensorDataset(X_train, train_masks, Y_train_topic)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data,\\\n",
        "                              sampler=train_sampler,\\\n",
        "                              batch_size=batchsize)\n",
        "\n",
        "validation_data = TensorDataset(X_valid, valid_masks, Y_valid_topic)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data,\\\n",
        "                                   sampler=validation_sampler,\\\n",
        "                                   batch_size=batchsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31RIu85cVNx3"
      },
      "source": [
        "#CREATE THE CLASSIFICATION MODEL\n",
        "class ElectraForMultiLabelSequenceClassification(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, pre_trained_model,num_labels_topics=2,num_labels_entent=2):\n",
        "    super(ElectraForMultiLabelSequenceClassification, self).__init__()\n",
        "    self.num_labels_topics = num_labels_topics\n",
        "    self.electra = pre_trained_model#Use the pretrqined model\n",
        "    self.layer1 = torch.nn.Linear(256, 1000)# add a linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.layer2  = torch.nn.Linear(1000, 2000)# add a linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.layer3  = torch.nn.Linear(2000, 3000)#change it to 5000 # add a linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.classifier_topics = torch.nn.Linear(3000, self.num_labels_topics)# add a linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.drop=torch.nn.Dropout(p=0.4)\n",
        "    self.leaky=torch.nn.ReLU()\n",
        "\n",
        "    torch.nn.init.xavier_normal_(self.classifier_topics.weight) #initialise the weight of th linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer1.weight) #initialise the weight of th linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer2.weight) #initialise the weight of th linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer3.weight) #initialise the weight of th linear layer\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels_topic=None,labels_entent=None):\n",
        "    # last hidden layer\n",
        "    last_hidden_state = self.electra(input_ids=input_ids,\\\n",
        "                                   attention_mask=attention_mask,\\\n",
        "                                   token_type_ids=token_type_ids)\n",
        "    # pool the outputs into a mean vector\n",
        "    mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
        "    l1 = self.leaky(self.layer1(mean_last_hidden_state))\n",
        "    l1=self.drop(l1)\n",
        "    l2 = self.leaky(self.layer2(l1))\n",
        "    l3 = self.leaky(self.layer3(l2))\n",
        "    l3=self.drop(l3)\n",
        "    logits_topics = torch.sigmoid(self.classifier_topics(l3))\n",
        "        \n",
        "    if labels_topic is not None:\n",
        "      loss_fct_topic = BCELoss()\n",
        "      loss1 = loss_fct_topic(logits_topics.view(-1, self.num_labels_topics),\\\n",
        "                      labels_topic.view(-1, self.num_labels_topics))\n",
        "      \n",
        "      \n",
        "      return loss1\n",
        "    else:\n",
        "      return logits_topics\n",
        "\n",
        "#This code borrow ideas from  :https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "  def pool_hidden_state(self, last_hidden_state):\n",
        "    \"\"\"\n",
        "    Pool the output vectors into a single mean vector \n",
        "    \"\"\"\n",
        "    last_hidden_state = last_hidden_state[0]\n",
        "    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
        "    return mean_last_hidden_state\n",
        "    \n",
        "  \n",
        "\n",
        "# len(Y_train[0]) = 6\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the learner model and define that it will be runing on the pre-defined device\n",
        "model = ElectraForMultiLabelSequenceClassification(pre_tained_model,num_labels_topics=len(Y_train_topic[0]))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "tkfKxuFA_c-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020999fa-be85-47ef-d62c-7c09b8973a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForMultiLabelSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(31238, 128)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer1): Linear(in_features=256, out_features=1000, bias=True)\n",
              "  (layer2): Linear(in_features=1000, out_features=2000, bias=True)\n",
              "  (layer3): Linear(in_features=2000, out_features=3000, bias=True)\n",
              "  (classifier_topics): Linear(in_features=3000, out_features=2464, bias=True)\n",
              "  (drop): Dropout(p=0.4, inplace=False)\n",
              "  (leaky): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK-IgfCyWhOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef63d58e-6fdd-4ff1-a590-e5a3bef04d53"
      },
      "source": [
        "#choose the learning optimizer algorithm\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01, correct_bias=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ridbti5JW8RA"
      },
      "source": [
        "#Define the training function ,The training method code is copied from this link : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "def train(model, num_epochs,\\\n",
        "          optimizer,\\\n",
        "          train_dataloader, valid_dataloader,\\\n",
        "          model_save_path,\\\n",
        "          train_loss_set=[], valid_loss_set = [],\\\n",
        "          lowest_eval_loss=None, start_epoch=0,\\\n",
        "          device=\"cpu\"\n",
        "          ):\n",
        "  \"\"\"\n",
        "  Train the model and save the model with the lowest validation loss\n",
        "  \"\"\"\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  for i in trange(num_epochs, desc=\"Epoch\"):\n",
        "    \n",
        "    actual_epoch = start_epoch + i\n",
        "\n",
        "    \n",
        "\n",
        "    model.train()\n",
        "\n",
        "    tr_loss = 0\n",
        "    num_train_samples = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels_topics = batch\n",
        "      # Clear out the gradients (by default they accumulate)\n",
        "      optimizer.zero_grad()\n",
        "      # Forward pass\n",
        "      loss = model(b_input_ids, attention_mask=b_input_mask, labels_topic=b_labels_topics)\n",
        "      # store train loss\n",
        "      tr_loss += loss.item()\n",
        "      num_train_samples += b_labels_topics.size(0)\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      # Update parameters and take a step using the computed gradient\n",
        "      optimizer.step()\n",
        "      #scheduler.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    epoch_train_loss = tr_loss/num_train_samples\n",
        "    train_loss_set.append(epoch_train_loss)\n",
        "\n",
        "    print(\"Train loss: {}\".format(epoch_train_loss))\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    # Put model in evaluation mode to evaluate loss on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss = 0\n",
        "    num_eval_samples = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in valid_dataloader:\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels_topics = batch\n",
        "      # Telling the model not to compute or store gradients,\n",
        "      # saving memory and speeding up validation\n",
        "      with torch.no_grad():\n",
        "        # Forward pass, calculate validation loss\n",
        "        loss= model(b_input_ids, attention_mask=b_input_mask, labels_topic=b_labels_topics)\n",
        "        # store valid loss\n",
        "        eval_loss += loss.item()\n",
        "        num_eval_samples += b_labels_topics.size(0)\n",
        "\n",
        "    epoch_eval_loss = eval_loss/num_eval_samples\n",
        "    valid_loss_set.append(epoch_eval_loss)\n",
        "\n",
        "    print(\"Valid loss: {}\".format(epoch_eval_loss))\n",
        "    \n",
        "    if lowest_eval_loss == None:\n",
        "      lowest_eval_loss = epoch_eval_loss\n",
        "      # save model\n",
        "      save_model(model, model_save_path, actual_epoch,\\\n",
        "                 lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    else:\n",
        "      if epoch_eval_loss < lowest_eval_loss:\n",
        "        lowest_eval_loss = epoch_eval_loss\n",
        "        # save model\n",
        "        save_model(model, model_save_path, actual_epoch,\\\n",
        "                   lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    print(\"\\n\")\n",
        "\n",
        "  return model, train_loss_set, valid_loss_set\n",
        "\n",
        "\n",
        "def save_model(model, save_path, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist):\n",
        "  \"\"\"\n",
        "  Save the model to the path directory provided\n",
        "  \"\"\"\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model\n",
        "  checkpoint = {'epochs': epochs, \\\n",
        "                'lowest_eval_loss': lowest_eval_loss,\\\n",
        "                'state_dict': model_to_save.state_dict(),\\\n",
        "                'train_loss_hist': train_loss_hist,\\\n",
        "                'valid_loss_hist': valid_loss_hist\n",
        "               }\n",
        "  torch.save(checkpoint, save_path)\n",
        "  print(\"Saving model at epoch {} with validation loss of {}\".format(epochs,\\\n",
        "                                                                     lowest_eval_loss))\n",
        "  return\n",
        "  \n",
        "def load_model(save_path):\n",
        "  \"\"\"\n",
        "  Load the model from the path directory provided\n",
        "  \"\"\"\n",
        "  checkpoint = torch.load(save_path)\n",
        "  model_state_dict = checkpoint['state_dict']\n",
        "  model = ElectraForMultiLabelSequenceClassification(num_labels=model_state_dict[\"classifier.weight\"].size()[0])\n",
        "  model.load_state_dict(model_state_dict)\n",
        "\n",
        "  epochs = checkpoint[\"epochs\"]\n",
        "  lowest_eval_loss = checkpoint[\"lowest_eval_loss\"]\n",
        "  train_loss_hist = checkpoint[\"train_loss_hist\"]\n",
        "  valid_loss_hist = checkpoint[\"valid_loss_hist\"]\n",
        "  \n",
        "  return model, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6NoScwbXq4g"
      },
      "source": [
        "# Define the saving path\n",
        "import os\n",
        "num_epochs=30\n",
        "\n",
        "cwd = os.getcwd()\n",
        "model_save_path = output_model_file = os.path.join(cwd, \"drive/MyDrive/Models/TopicPrediction/TGD_Classification_Concatenate_Both_Topic_Entent_Sigmoid_2Essay.bin\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = output_model_file = os.path.join(cwd, \"drive/MyDrive/Models/TopicPrediction/TGD_Classification_Concatenate_Both_Topic_Entent_Sigmoid.bin\")\n"
      ],
      "metadata": {
        "id": "U4Fu5tfmNmRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BdgIZQVzSh2",
        "outputId": "f59eed28-9f1f-4815-c013-78cd6ccf7a92"
      },
      "source": [
        "#Train the model\n",
        "model, train_loss_set, valid_loss_set = train(model=model,\\\n",
        "                                              num_epochs=num_epochs,\\\n",
        "                                              optimizer=optimizer,\\\n",
        "                                              train_dataloader=train_dataloader,\\\n",
        "                                              valid_dataloader=validation_dataloader,\\\n",
        "                                              model_save_path=model_save_path,\\\n",
        "                                              device=device)\n",
        "#0.016783231785479146"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.0004201373413772305\n",
            "Valid loss: 0.00017138624336803928\n",
            "Saving model at epoch 0 with validation loss of None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   3%|▎         | 1/30 [25:56<12:32:27, 1556.80s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 0 with validation loss of 0.00017138624336803928\n",
            "\n",
            "\n",
            "Train loss: 0.00015501507338890023\n",
            "Valid loss: 0.00012067284470362134\n",
            "Saving model at epoch 1 with validation loss of 0.00017138624336803928\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   7%|▋         | 2/30 [51:49<12:05:25, 1554.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 1 with validation loss of 0.00012067284470362134\n",
            "\n",
            "\n",
            "Train loss: 0.00011375443702992227\n",
            "Valid loss: 0.00010361205581508\n",
            "Saving model at epoch 2 with validation loss of 0.00012067284470362134\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 3/30 [1:17:42<11:39:11, 1553.76s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 2 with validation loss of 0.00010361205581508\n",
            "\n",
            "\n",
            "Train loss: 9.507469857662288e-05\n",
            "Valid loss: 9.535525540650306e-05\n",
            "Saving model at epoch 3 with validation loss of 0.00010361205581508\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  13%|█▎        | 4/30 [1:43:37<11:13:27, 1554.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 3 with validation loss of 9.535525540650306e-05\n",
            "\n",
            "\n",
            "Train loss: 8.407177411744762e-05\n",
            "Valid loss: 9.001477717885675e-05\n",
            "Saving model at epoch 4 with validation loss of 9.535525540650306e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  17%|█▋        | 5/30 [2:09:33<10:47:50, 1554.81s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 4 with validation loss of 9.001477717885675e-05\n",
            "\n",
            "\n",
            "Train loss: 7.647463522143203e-05\n",
            "Valid loss: 8.788407630266487e-05\n",
            "Saving model at epoch 5 with validation loss of 9.001477717885675e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 6/30 [2:35:25<10:21:35, 1553.99s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 5 with validation loss of 8.788407630266487e-05\n",
            "\n",
            "\n",
            "Train loss: 7.085897373352703e-05\n",
            "Valid loss: 8.490596413422412e-05\n",
            "Saving model at epoch 6 with validation loss of 8.788407630266487e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  23%|██▎       | 7/30 [3:01:17<9:55:28, 1553.41s/it] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 6 with validation loss of 8.490596413422412e-05\n",
            "\n",
            "\n",
            "Train loss: 6.622308187557872e-05\n",
            "Valid loss: 8.402390412577389e-05\n",
            "Saving model at epoch 7 with validation loss of 8.490596413422412e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  27%|██▋       | 8/30 [3:27:11<9:29:36, 1553.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 7 with validation loss of 8.402390412577389e-05\n",
            "\n",
            "\n",
            "Train loss: 6.233845483841988e-05\n",
            "Valid loss: 8.110178877911354e-05\n",
            "Saving model at epoch 8 with validation loss of 8.402390412577389e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 9/30 [3:53:05<9:03:43, 1553.49s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 8 with validation loss of 8.110178877911354e-05\n",
            "\n",
            "\n",
            "Train loss: 5.90523427519778e-05\n",
            "Valid loss: 8.300159359781772e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|███▎      | 10/30 [4:18:55<8:37:32, 1552.62s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 9 with validation loss of 8.110178877911354e-05\n",
            "\n",
            "\n",
            "Train loss: 5.599906935988396e-05\n",
            "Valid loss: 7.972969272770606e-05\n",
            "Saving model at epoch 10 with validation loss of 8.110178877911354e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  37%|███▋      | 11/30 [4:44:47<8:11:32, 1552.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 10 with validation loss of 7.972969272770606e-05\n",
            "\n",
            "\n",
            "Train loss: 5.356114655250236e-05\n",
            "Valid loss: 7.980023282357787e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 12/30 [5:10:36<7:45:24, 1551.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 11 with validation loss of 7.972969272770606e-05\n",
            "\n",
            "\n",
            "Train loss: 5.089543151120999e-05\n",
            "Valid loss: 7.90289420831543e-05\n",
            "Saving model at epoch 12 with validation loss of 7.972969272770606e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  43%|████▎     | 13/30 [5:36:25<7:19:22, 1550.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 12 with validation loss of 7.90289420831543e-05\n",
            "\n",
            "\n",
            "Train loss: 4.8590313473371095e-05\n",
            "Valid loss: 7.860221044314169e-05\n",
            "Saving model at epoch 13 with validation loss of 7.90289420831543e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  47%|████▋     | 14/30 [6:02:15<6:53:27, 1550.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 13 with validation loss of 7.860221044314169e-05\n",
            "\n",
            "\n",
            "Train loss: 4.665278731657611e-05\n",
            "Valid loss: 7.927582443082556e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 15/30 [6:28:06<6:27:41, 1550.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 14 with validation loss of 7.860221044314169e-05\n",
            "\n",
            "\n",
            "Train loss: 4.43817646815805e-05\n",
            "Valid loss: 7.685078192383838e-05\n",
            "Saving model at epoch 15 with validation loss of 7.860221044314169e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  53%|█████▎    | 16/30 [6:53:58<6:01:53, 1550.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 15 with validation loss of 7.685078192383838e-05\n",
            "\n",
            "\n",
            "Train loss: 4.2533635858891034e-05\n",
            "Valid loss: 7.69535691089485e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  57%|█████▋    | 17/30 [7:19:49<5:36:02, 1550.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 16 with validation loss of 7.685078192383838e-05\n",
            "\n",
            "\n",
            "Train loss: 4.128083443570479e-05\n",
            "Valid loss: 7.947984276625898e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 18/30 [7:45:39<5:10:09, 1550.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 17 with validation loss of 7.685078192383838e-05\n",
            "\n",
            "\n",
            "Train loss: 3.9456961014635996e-05\n",
            "Valid loss: 7.943999954982779e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  63%|██████▎   | 19/30 [8:11:33<4:44:27, 1551.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 18 with validation loss of 7.685078192383838e-05\n",
            "\n",
            "\n",
            "Train loss: 3.8033603263471065e-05\n",
            "Valid loss: 7.664176486992491e-05\n",
            "Saving model at epoch 19 with validation loss of 7.685078192383838e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 20/30 [8:37:28<4:18:46, 1552.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 19 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 3.666714905906087e-05\n",
            "Valid loss: 7.716681876249468e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  70%|███████   | 21/30 [9:03:22<3:52:58, 1553.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 20 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 3.525385641386173e-05\n",
            "Valid loss: 8.054210932473176e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  73%|███████▎  | 22/30 [9:29:17<3:27:08, 1553.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 21 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 3.379128681317674e-05\n",
            "Valid loss: 7.844923279487616e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  77%|███████▋  | 23/30 [9:55:12<3:01:18, 1554.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 22 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 3.274250383794198e-05\n",
            "Valid loss: 8.062166045549985e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 24/30 [10:21:06<2:35:24, 1554.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 23 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 3.1600602152595834e-05\n",
            "Valid loss: 7.834821879137959e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  83%|████████▎ | 25/30 [10:47:02<2:09:33, 1554.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 24 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 3.0420367561283286e-05\n",
            "Valid loss: 8.327019229893805e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  87%|████████▋ | 26/30 [11:12:55<1:43:36, 1554.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 25 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 2.957210914255487e-05\n",
            "Valid loss: 8.072672394435886e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  90%|█████████ | 27/30 [11:38:49<1:17:42, 1554.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 26 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 2.8592121040584792e-05\n",
            "Valid loss: 7.940310421431801e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  93%|█████████▎| 28/30 [12:04:43<51:48, 1554.10s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 27 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 2.776455946040376e-05\n",
            "Valid loss: 7.777313138253448e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  97%|█████████▋| 29/30 [12:30:39<25:54, 1554.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 28 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n",
            "Train loss: 2.6867796875626645e-05\n",
            "Valid loss: 7.779156769456906e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 30/30 [12:56:32<00:00, 1553.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 29 with validation loss of 7.664176486992491e-05\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khzjKA6Z-z6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0795e2af-eee7-4c8d-ca4a-2a32fa77527c"
      },
      "source": [
        "#Restore the best version of the trained model\n",
        "#This code is borrowed from this link : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "checkpoint = torch.load(model_save_path)\n",
        "model_state_dict = checkpoint['state_dict']\n",
        "model = ElectraForMultiLabelSequenceClassification(pre_tained_model,num_labels_topics=model_state_dict[\"classifier_topics.weight\"].size()[0])\n",
        "model.load_state_dict(model_state_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrB3xNiqX8fJ"
      },
      "source": [
        "#Create a function to generate tpic prediction from a given text\n",
        "##This code borrow ideas from : https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "def generate_predictions(model, features,mask, num_labels, device=\"cpu\", batch_size=32):\n",
        "  num_iter = math.ceil(features.shape[0]/batch_size)\n",
        "  \n",
        "  pred_probs = np.array([]).reshape(0, num_labels)\n",
        "  \n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  \n",
        "  for i in range(num_iter):\n",
        "    X = features[i*batch_size:(i+1)*batch_size,:]\n",
        "    masks = mask[i*batch_size:(i+1)*batch_size,:]\n",
        "    X = X.to(device)\n",
        "    masks = masks.to(device)\n",
        "    with torch.no_grad():\n",
        "      logits = model(input_ids=X, attention_mask=masks)\n",
        "      #logits = logits.sigmoid().detach().cpu().numpy()\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      pred_probs = np.vstack([pred_probs, logits])\n",
        "  \n",
        "  return pred_probs\n",
        "  \n",
        "num_labels = len(valid_labels_vector[0])\n",
        "pred_probs = generate_predictions(model, test_input_ids,test_attention_masks, num_labels, device=device, batch_size=32)\n",
        "prob=np.round(pred_probs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate the results "
      ],
      "metadata": {
        "id": "k0c2wuPLF2ua"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sILrob72FfnP",
        "outputId": "146d30db-6829-453a-e15f-7a8e414c5798"
      },
      "source": [
        "from sklearn.metrics import label_ranking_average_precision_score,precision_score,recall_score,f1_score,accuracy_score,roc_auc_score\n",
        "label_ranking_average_precision_score(y_test_topic_vector, prob) \n",
        "#0.9027679914144469\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9027679914144469"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test_topic_vector, prob) \n",
        "#0.7983176036109971"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIK58mKhgdFu",
        "outputId": "3721754f-f2a7-41bd-974a-2883535cb0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7983176036109971"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_test_topic_vector, prob,average=\"micro\") \n",
        "#0.9606383814826487"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRE0I6EbghFQ",
        "outputId": "2af5f0ab-a372-40c5-c565-fede4ebfe4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9606383814826487"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_test_topic_vector, prob,average=\"micro\") \n",
        "#0.9692994051553205"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY4_gYTugUoh",
        "outputId": "b4b57ca8-1949-41d8-dde9-59d1145d1d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9692994051553205"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ook_ZEGe5UKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46042023-1c84-416a-a50b-28bd652002ea"
      },
      "source": [
        "precision_score(y_test_topic_vector, prob,average=\"macro\") \n",
        "#0.16962602821072634\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16962602821072634"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(y_test_topic_vector, prob,average=\"micro\") \n",
        "#0.9213154918959668"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbgIyHiAgnSZ",
        "outputId": "df886fc8-cdd0-44a8-ded7-2d068c891e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9213154918959668"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test_topic_vector, prob,average=\"micro\") \n",
        "#0.9446985313063644"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlaTxculf3p8",
        "outputId": "2a32cc61-e31f-4054-d024-dd0752f0431b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9446985313063644"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define hit@n  algorithm \n",
        "\n",
        "def hit(data_predicted=pred_probs,data_real=y_test_topic_vector,n=1):\n",
        "\n",
        "  hit=0\n",
        "\n",
        "\n",
        "  for i,p in enumerate(y_test_topic_vector):\n",
        "    real_indexes=[j for j,i in enumerate(p) if i ==1]\n",
        "    original_topics=\" \".join(topic_list[x] for x in real_indexes)\n",
        "    #print(f\" real topics: {original_topics}\")\n",
        "    \n",
        "    prob=pred_probs[i].argsort()[-n*len(real_indexes):][::-1]\n",
        "    predicted_topics=\" \".join(topic_list[x] for x in prob)\n",
        "    #print(f\" predicted topics: {predicted_topics}\")\n",
        "    check =  all(item in prob for item in real_indexes)\n",
        "    if (check ==True):\n",
        "      hit=hit+1\n",
        "  #print(hit/len(y_test_topic_vector))\n",
        "  return hit/len(y_test_topic_vector)\n"
      ],
      "metadata": {
        "id": "cYy5s39SWO7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the Hit@1 results\n",
        "result=hit(data_predicted=pred_probs,data_real=y_test_topic_vector,n=1)\n",
        "result\n",
        "#0.8359663520722199"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sICdZmPqroH",
        "outputId": "03aa5bea-9bc0-4342-829c-923884ddbd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8359663520722199"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the Hit@3 results\n",
        "\n",
        "result=hit(data_predicted=pred_probs,data_real=y_test_topic_vector,n=3)\n",
        "result\n",
        "#0.9070578580221584"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl1VQ-A1qstJ",
        "outputId": "4f94cf63-4750-4c9a-9879-14c212d57e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9070578580221584"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the Hit@5 results\n",
        "\n",
        "result=hit(data_predicted=pred_probs,data_real=y_test_topic_vector,n=5)\n",
        "result\n",
        "#0.9191629052113254\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpI8XEUiqs69",
        "outputId": "ebec4ca7-a734-46b6-ec05-d5604cb638ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9191629052113254"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the Hit@10 results\n",
        "\n",
        "result=hit(data_predicted=pred_probs,data_real=y_test_topic_vector,n=10)\n",
        "result\n",
        "#0.9344480919162905\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnLCkAQFqwoe",
        "outputId": "e4930173-b8dc-4bae-9631-def969b40133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9344480919162905"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}