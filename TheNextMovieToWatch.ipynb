{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSDezoagD0rG",
        "outputId": "5ed610f9-7627-45a5-e28c-0465d4586474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahzlzPkbaKql"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws9y5SKK151x",
        "outputId": "bc574ff4-615b-4c04-b124-ad684d042878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 31.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.5)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[K     |████████████████████████████████| 398 kB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Collecting typing-extensions>=4.0.0\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 66.9 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.63.0)\n",
            "Collecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 68.3 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 66.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 67.1 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, PyYAML, pytorch-lightning\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.0 torchmetrics-0.7.3 typing-extensions-4.1.1 yarl-1.7.2\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 27.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 58.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n",
            "Collecting dataset\n",
            "  Downloading dataset-1.5.2-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from dataset) (1.4.32)\n",
            "Collecting banal>=1.0.1\n",
            "  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
            "Collecting alembic>=0.6.2\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 37.3 MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (4.11.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.2->dataset) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.0.1)\n",
            "Installing collected packages: Mako, banal, alembic, dataset\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 banal-1.0.6 dataset-1.5.2\n"
          ]
        }
      ],
      "source": [
        "#Install the necessary libraries\n",
        "!pip install pytorch_lightning\n",
        "!pip install transformers\n",
        "!pip install dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYLnw-bX2vn9"
      },
      "outputs": [],
      "source": [
        "#import the necessary packages\n",
        "import pickle\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "from torch.nn import BCEWithLogitsLoss,MSELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import DistilBertTokenizer, DistilBertForMaskedLM,AdamW\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJoOCSPSDqC5"
      },
      "outputs": [],
      "source": [
        "#Get the data \n",
        "with open('./drive/MyDrive/Data/English_TGD2_TGD_All_data.pkl','rb') as file:\n",
        "    TGD_All_data=pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0I9GpI65kz2"
      },
      "outputs": [],
      "source": [
        "# get all the movie names and ids in our dataset so that we will add them later to the Pre-trained model vocabulary\n",
        "TGD_movie_names=[v['name'] for k, v in TGD_All_data['all_movies'].items()]\n",
        "TGD_movie_ids=[k for k, v in TGD_All_data['all_movies'].items()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtH8FRvHcS78"
      },
      "outputs": [],
      "source": [
        "# reshape all the movies for each user in a sequence way. example:\"user1\" : @movie1,@movie2,@movie3 ...\n",
        "def create_rows_movie_sequences(TGD_All_data,typee='train'):\n",
        "  list_of_all_sequences=[]\n",
        "  for i, dial in enumerate(TGD_All_data[typee]):\n",
        "    movies_seq= dial['user_history_movies_interaction_ids']\n",
        "    movies_seq=' '.join(x for x in movies_seq)\n",
        "    if movies_seq=='':\n",
        "      continue\n",
        "    else:\n",
        "      list_of_all_sequences.append(movies_seq)\n",
        "  \n",
        "  return list_of_all_sequences\n",
        "\n",
        "train_list_of_sequences=create_rows_movie_sequences(TGD_All_data,typee='train')\n",
        "test_list_of_sequences=create_rows_movie_sequences(TGD_All_data,typee='test')\n",
        "valid_list_of_sequences=create_rows_movie_sequences(TGD_All_data,typee='valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vyorvqbt4DSq"
      },
      "outputs": [],
      "source": [
        "# create the train, test, and validation dataframes\n",
        "train_df= pd.DataFrame({'interactions':train_list_of_sequences})\n",
        "test_df= pd.DataFrame({'interactions':test_list_of_sequences})\n",
        "valid_df= pd.DataFrame({'interactions':valid_list_of_sequences})\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYegL2xj8gw4"
      },
      "outputs": [],
      "source": [
        "#randomly shuffle the dataset\n",
        "from sklearn.utils import shuffle\n",
        "train_df=shuffle(train_df)\n",
        "test_df=shuffle(test_df)\n",
        "valid_df=shuffle(valid_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_YAaQtjtmGc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "5725cf74f3f64775ae71290742038ec4",
            "17937c0a4f194cdaaa6c0ca083671d90",
            "fdef7074008e47579d630f9a9d033578",
            "ab2fd22206064cc1bc7ccefeb9867b83",
            "b92f7d57097547ea888476fe12608059",
            "dbb6e7028d104829a4787bffc3438ede",
            "fc1bdf6187124f1aa5c416833c2a1eb6",
            "b9f59da6f3fd4e04a3b372a7ee444b03",
            "176489304bf745dbaa7a2e85d42abb2d",
            "eb42fe2393bb417ba2c8c275882e9331",
            "a5b2d2293b3f433b841a15cf78ca4b30",
            "c79cdc4883b241b39a8d3585cdccbd95",
            "985cada323ee456b9450e26562af8939",
            "d2adcd244c4f4defbc9426df5a7fe893",
            "396255faa03245c4b17f27c0018c1420",
            "4c59c1de03764422aa88df9d01be3264",
            "e28f4e9881c94753a36ffa8d6aabc4a4",
            "8df13ed85dc94e0caa7a318bd6e40d18",
            "1c2e4519fa6f451e96df850b8b6f5c3f",
            "29fafae2e9b8410baa498f541c6797f6",
            "b08323ff0b744687bf29dbb92d8e3a13",
            "de0041f0571048159dbc4bb420abf1d6",
            "fac72d0b8b7544f0823eb4341b7a0c3e",
            "3263d8fefd6c4b46911f60786f82829e",
            "ad6878793872432d8de0c146a0c717b7",
            "2f15fade43554ce5a502d43a07e76d9d",
            "9cbe54f357aa49bb9b815d68766d28fa",
            "fa474595e1b244c3a823d5abd8f9a15a",
            "e6b84502351443c79d80dfd402094f1f",
            "412561628438416db915e58d2c4e57b0",
            "2d9ad211477a45a687c3f2d54ddb8472",
            "8e22af82d7774125a57cc958bff342bb",
            "34a91dc2e4154bb7b37d650818ac124a"
          ]
        },
        "id": "yojBHpfl6l1d",
        "outputId": "21214877-37b9-4558-cd5f-a6e56c25e99c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5725cf74f3f64775ae71290742038ec4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c79cdc4883b241b39a8d3585cdccbd95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fac72d0b8b7544f0823eb4341b7a0c3e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Instansiate the distilbert tokenizer and add the movie name to the vocabulary\n",
        "tokenizer_4rec = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "num_added_toks = tokenizer_4rec.add_tokens(TGD_movie_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyT7KNm6mNDR"
      },
      "outputs": [],
      "source": [
        "#Create a dictionary in the form of  movie_id:movie_name\n",
        "idtotoken={value:key for key,value in tokenizer_4rec.get_vocab().items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zip7X7ZwcPbT"
      },
      "outputs": [],
      "source": [
        "# create a function to tokenize the movie sequences\n",
        "def sequence_Input_Tokenization(liste, tokenizer):\n",
        "    \n",
        "    outputs = tokenizer(liste,truncation=True,return_tensors='pt',return_attention_mask=True,max_length=512, padding='max_length')    \n",
        "    outputs['labels']=outputs.input_ids.detach().clone()\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx6to7279VTt"
      },
      "outputs": [],
      "source": [
        "#for each user we keep only the movie sequences \n",
        "train_data=train_df['interactions']\n",
        "test_data=test_df['interactions']\n",
        "valid_data=valid_df['interactions']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2gkXHawBZYM",
        "outputId": "ae0a3a98-25ee-485b-cf84-f87bd1f12b29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8328"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#store the tokenizer \n",
        "\n",
        "tokenizer_4rec.save_pretrained('drive/MyDrive/Models/NextMovie/Tokenizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duwQtQp31HlH",
        "outputId": "5e2617d5-136b-45cd-84cc-d51c7d69fd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('drive/MyDrive/Models/NextMovie/Tokenizer/tokenizer_config.json',\n",
              " 'drive/MyDrive/Models/NextMovie/Tokenizer/special_tokens_map.json',\n",
              " 'drive/MyDrive/Models/NextMovie/Tokenizer/vocab.txt',\n",
              " 'drive/MyDrive/Models/NextMovie/Tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fEQLMpiTTbf"
      },
      "outputs": [],
      "source": [
        "MLM_train_inputs=sequence_Input_Tokenization(list(train_data.values), tokenizer_4rec) # tokenize the training set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8k5gaG5UGRg"
      },
      "outputs": [],
      "source": [
        "MLM_test_inputs=sequence_Input_Tokenization(list(test_data.values), tokenizer_4rec)# tokenize the testing set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkUP6ReIEohL"
      },
      "outputs": [],
      "source": [
        "MLM_valid_inputs=sequence_Input_Tokenization(list(valid_data.values), tokenizer_4rec) # tokenize the validation set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StQgjGBa9rzy"
      },
      "outputs": [],
      "source": [
        "#Create the first type of inputs : The first network input : the Cusal network input\n",
        "# Mask random 15% movies for each sequence \n",
        "#This code borrow ideas from : https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c\n",
        "def mask_train_data(inputs):\n",
        "  rand=torch.rand(inputs.input_ids.shape)\n",
        "  maskArray= (rand<0.15) *(inputs.input_ids!=tokenizer_4rec.get_vocab()['[CLS]'])*(inputs.input_ids!=tokenizer_4rec.get_vocab()['[SEP]'])*(inputs.input_ids!=tokenizer_4rec.get_vocab()['[PAD]'])\n",
        "  selection=[]\n",
        "  for i in range(inputs.input_ids.shape[0]):\n",
        "    indexesThatShouldBeMasked=torch.flatten(maskArray[i].nonzero()).tolist()\n",
        "    selection.append(indexesThatShouldBeMasked)#\n",
        "    inputs.input_ids[i,indexesThatShouldBeMasked]=tokenizer_4rec.get_vocab()['[MASK]'] # maske the input\n",
        "  return inputs\n",
        "MLM_train_inputs=mask_train_data(MLM_train_inputs)\n",
        "MLM_valid_inputs=mask_train_data(MLM_valid_inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80ytApYBzo53"
      },
      "outputs": [],
      "source": [
        "#Create the second type of inputs : the second network iinput: the prefix network input\n",
        "# Mask only the last movie for each sequence of movies \n",
        "MLM_train_inputs_mask_last_input_ids = MLM_train_inputs.input_ids.detach().clone()\n",
        "MLM_train_inputs_mask_last_mask = MLM_train_inputs.attention_mask.detach().clone()\n",
        "MLM_train_inputs_mask_last_labels = MLM_train_inputs.labels.detach().clone()\n",
        "MLM_valid_inputs_mask_last_input_ids = MLM_valid_inputs.input_ids.detach().clone()\n",
        "MLM_valid_inputs_mask_last_mask = MLM_valid_inputs.attention_mask.detach().clone()\n",
        "MLM_valid_inputs_mask_last_labels = MLM_valid_inputs.labels.detach().clone()\n",
        "def mask_last_train_data(inputs):\n",
        "\n",
        "  rand=torch.rand(inputs.shape)\n",
        "  maskArray= (rand<0.15) *(inputs!=tokenizer_4rec.get_vocab()['[CLS]'])*(inputs!=tokenizer_4rec.get_vocab()['[SEP]'])*(inputs!=tokenizer_4rec.get_vocab()['[PAD]'])\n",
        "  selection=[]\n",
        "  for i in range(inputs.shape[0]):\n",
        "    index_sep=(inputs[i] == tokenizer_4rec.get_vocab()['[SEP]']).nonzero(as_tuple=True)[0]\n",
        "    inputs[i,index_sep-1]=tokenizer_4rec.get_vocab()['[MASK]'] # masker the last element input  return inputs\n",
        "\n",
        "  return inputs\n",
        "MLM_train_inputs_mask_last_input_ids=mask_last_train_data(MLM_train_inputs_mask_last_input_ids)\n",
        "MLM_valid_inputs_mask_last_input_ids=mask_last_train_data(MLM_valid_inputs_mask_last_input_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL9ocsItUQh_"
      },
      "outputs": [],
      "source": [
        "# change the names of our input and labels for simplicity\n",
        "\n",
        "MLM_X_train,MLM_train_masks,MLM_Y_train, = (MLM_train_inputs.input_ids,MLM_train_inputs.attention_mask,MLM_train_inputs.labels)\n",
        "MLM_X_valid,MLM_valid_masks,MLM_Y_valid = (MLM_valid_inputs.input_ids,MLM_valid_inputs.attention_mask,MLM_valid_inputs.labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAJmRw-QVDdH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Formulate the input in the batch form to pass it for the pytorch neural network framework\n",
        "batch_size=5\n",
        "MLM_train_data = TensorDataset(MLM_X_train,MLM_train_masks,MLM_Y_train,MLM_train_inputs_mask_last_input_ids,MLM_train_inputs_mask_last_mask,MLM_train_inputs_mask_last_labels)\n",
        "MLM_train_sampler = RandomSampler(MLM_train_data)\n",
        "MLM_train_dataloader = DataLoader(MLM_train_data,\\\n",
        "                              sampler=MLM_train_sampler,\\\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "MLM_validation_data = TensorDataset(MLM_X_valid,MLM_valid_masks,MLM_Y_valid,MLM_valid_inputs_mask_last_input_ids,MLM_valid_inputs_mask_last_mask,MLM_valid_inputs_mask_last_labels)\n",
        "MLM_validation_sampler = SequentialSampler(MLM_validation_data)\n",
        "MLM_validation_dataloader = DataLoader(MLM_validation_data,\\\n",
        "                                   sampler=MLM_validation_sampler,\\\n",
        "                                   batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MITK37c7cYWV"
      },
      "outputs": [],
      "source": [
        "# define the training device \n",
        "device =torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBziM_AB04U4"
      },
      "source": [
        "#OnlyNextItemToPredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21WbF7aICI4k"
      },
      "outputs": [],
      "source": [
        "#Create our model\n",
        "class DistilBert_TGD_Ensemble_no_BIG5(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(DistilBert_TGD_Ensemble_no_BIG5, self).__init__()\n",
        "    \n",
        "    model=DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')# Instanciate the first DistilBer model (Causal)\n",
        "    model.resize_token_embeddings(len(tokenizer_4rec))# Update the covabulary of the pre-trqined model to match the vocabulary of the tokenizer\n",
        "\n",
        "\n",
        "    model_mask_last=DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased') # Instanciate the second DistilBer model (Prefix)\n",
        "    model_mask_last.resize_token_embeddings(len(tokenizer_4rec))# Update the covabulary of the pre-trqined model to match the vocabulary of the tokenizer\n",
        "\n",
        "\n",
        "    self.electra = model\n",
        "    self.electra_mask_last = model_mask_last\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "   \n",
        "  def forward(self, input_ids, token_type_ids=None,attention_mask=None, labels=None,input_ids_mask_last=None, token_type_ids_mask_last=None,attention_mask_mask_last=None, labels_mask_last=None):\n",
        "    #Now that we defined the architecture and initialized the weights we need to define the forward function\n",
        "    #and how each defined variable will be used in the architecture\n",
        "    \n",
        "    \n",
        "    \n",
        "    position_ids=torch.arange(start=0, end = input_ids.shape[1], step=1).expand_as(input_ids).to(device)\n",
        "    \n",
        "   \n",
        "    # last hidden layer\n",
        "    #for ech row we will use the ELECTRa model to create an embedding vector given the tokenized input\n",
        "\n",
        "\n",
        "    #Electra predfoned positions\n",
        "\n",
        "    MLM_outputs = self.electra(input_ids, attention_mask=attention_mask,labels=labels)\n",
        "    self.electra_mask_last.state_dict()['vocab_layer_norm.bias']=self.electra.state_dict()['vocab_layer_norm.bias']\n",
        "\n",
        "    MLM_outputs_mask_last= self.electra_mask_last(input_ids_mask_last, attention_mask=attention_mask_mask_last,labels=labels_mask_last)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    if ((labels is not None) ):\n",
        "\n",
        "\n",
        "      loss=(MLM_outputs.loss + MLM_outputs_mask_last.loss)\n",
        "      return loss\n",
        "    else:\n",
        "      return MLM_outputs.logits,MLM_outputs_mask_last.logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BY4x2QXNRt2w"
      },
      "outputs": [],
      "source": [
        "#Define the storing path and the trqining epochs\n",
        "num_epochs=20\n",
        "\n",
        "cwd = os.getcwd()\n",
        "model_save_path = output_model_file = os.path.join(cwd, \"drive/MyDrive/Models/NextMovie/DistilBert_TGD_Ensemble_no_BIG5_last_masked_and_NormalMask_OnlyNextItemToPredict.bin\")# badlouu fi drixe explicitemnt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "50e78c239b74430ba55843387dc3a169",
            "e316a1efa9734671b2b51702497fc523",
            "d0a4d25ae00d4e16a34bf6212d9b06a5",
            "b9da2ce48e0d43708af23c9c46462f48",
            "169d9b88fca84987831632dadf05c369",
            "287bba878a724b63b5ab403437ed6808",
            "308e07b431ea440cbeabed22dfa0c736",
            "9b61d35a5a7e4a2fa9b9dcb66a2e54d6",
            "b3d12db0406d4ae9b778c34038746b8f",
            "07639f7954f745eeb6166943745df805",
            "1f1795092eb8422db7723ecd434a4346"
          ]
        },
        "id": "_oN-iBgO0-7u",
        "outputId": "8892d99c-7c2c-493b-cb41-8904e917a2a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50e78c239b74430ba55843387dc3a169"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBert_TGD_Ensemble_no_BIG5(\n",
              "  (distilbert): DistilBertForMaskedLM(\n",
              "    (distilbert): DistilBertModel(\n",
              "      (embeddings): Embeddings(\n",
              "        (word_embeddings): Embedding(64356, 768)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (transformer): Transformer(\n",
              "        (layer): ModuleList(\n",
              "          (0): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (vocab_projector): Linear(in_features=768, out_features=64356, bias=True)\n",
              "    (mlm_loss_fct): CrossEntropyLoss()\n",
              "  )\n",
              "  (distilbert_mask_last): DistilBertForMaskedLM(\n",
              "    (distilbert): DistilBertModel(\n",
              "      (embeddings): Embeddings(\n",
              "        (word_embeddings): Embedding(64356, 768)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (transformer): Transformer(\n",
              "        (layer): ModuleList(\n",
              "          (0): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (vocab_projector): Linear(in_features=768, out_features=64356, bias=True)\n",
              "    (mlm_loss_fct): CrossEntropyLoss()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# instanciate our model\n",
        "model = DistilBert_TGD_Ensemble_no_BIG5()\n",
        "model.to(device) # specify that the model will be running on the perdefined device that we have \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHxRDaMf0-7u"
      },
      "outputs": [],
      "source": [
        "#Define the training function : this code is copied from https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "\n",
        "def train(model, num_epochs,\\\n",
        "          optimizer,\\\n",
        "          train_dataloader, valid_dataloader,\\\n",
        "          model_save_path,\\\n",
        "          train_loss_set=[], valid_loss_set = [],\\\n",
        "          lowest_eval_loss=None, start_epoch=0,\\\n",
        "          device=\"cpu\"\n",
        "          ):\n",
        "  \"\"\"\n",
        "  Train the model and save the model with the lowest validation loss\n",
        "  \"\"\"\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  for i in trange(num_epochs, desc=\"Epoch\"):\n",
        "    \n",
        "    actual_epoch = start_epoch + i\n",
        "\n",
        "    \n",
        "\n",
        "    model.train()\n",
        "\n",
        "    tr_loss = 0\n",
        "    num_train_samples = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels,mask_last_input_ids,mask_last_attention_mask,mask_last_labels= batch\n",
        "      # Clear out the gradients (by default they accumulate)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      # Forward pass\n",
        "      loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels,input_ids_mask_last=mask_last_input_ids,attention_mask_mask_last=mask_last_attention_mask,labels_mask_last=mask_last_labels)\n",
        "      # store train loss\n",
        "      tr_loss += loss.item()\n",
        "      num_train_samples += b_labels.size(0)\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      # Update parameters and take a step using the computed gradient/\n",
        "      optimizer.step()\n",
        "      #scheduler.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    epoch_train_loss = tr_loss/num_train_samples\n",
        "    train_loss_set.append(epoch_train_loss)\n",
        "\n",
        "    print(\"Train loss: {}\".format(epoch_train_loss))\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    # Put model in evaluation mode to evaluate loss on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss = 0\n",
        "    num_eval_samples = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in valid_dataloader:\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels,mask_last_input_ids,mask_last_attention_mask,mask_last_labels= batch\n",
        "      # Telling the model not to compute or store gradients,\n",
        "      # saving memory and speeding up validation\n",
        "      with torch.no_grad():\n",
        "        # Forward pass, calculate validation loss\n",
        "        loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels,input_ids_mask_last=mask_last_input_ids,attention_mask_mask_last=mask_last_attention_mask,labels_mask_last=mask_last_labels)\n",
        "        eval_loss += loss.item()\n",
        "        num_eval_samples += b_labels.size(0)\n",
        "\n",
        "    epoch_eval_loss = eval_loss/num_eval_samples\n",
        "    valid_loss_set.append(epoch_eval_loss)\n",
        "\n",
        "    print(\"Valid loss: {}\".format(epoch_eval_loss))\n",
        "\n",
        "\n",
        "    if lowest_eval_loss == None:\n",
        "      lowest_eval_loss = epoch_eval_loss\n",
        "      # save model\n",
        "      save_model(model, model_save_path, actual_epoch,\\\n",
        "                 lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    else:\n",
        "      if epoch_eval_loss < lowest_eval_loss:\n",
        "        lowest_eval_loss = epoch_eval_loss\n",
        "        # save model\n",
        "        save_model(model, model_save_path, actual_epoch,\\\n",
        "                   lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    print(\"\\n\")\n",
        "\n",
        "  return model, train_loss_set, valid_loss_set\n",
        "\n",
        "\n",
        "def save_model(model, save_path, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist):\n",
        "  \"\"\"\n",
        "  Save the model to the path directory provided\n",
        "  \"\"\"\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model\n",
        "  checkpoint = {'epochs': epochs, \\\n",
        "                'lowest_eval_loss': lowest_eval_loss,\\\n",
        "                'state_dict': model_to_save.state_dict(),\\\n",
        "                'train_loss_hist': train_loss_hist,\\\n",
        "                'valid_loss_hist': valid_loss_hist\n",
        "               }\n",
        "  torch.save(checkpoint, save_path)\n",
        "  print(\"Saving model at epoch {} with validation loss of {}\".format(epochs,\\\n",
        "                                                                     lowest_eval_loss))\n",
        "  return\n",
        "  \n",
        "def load_model(save_path):\n",
        "  \"\"\"\n",
        "  Load the model from the path directory provided\n",
        "  \"\"\"\n",
        "  checkpoint = torch.load(save_path)\n",
        "  model_state_dict = checkpoint['state_dict']\n",
        "  model = DistilBert_TGD_Ensemble_no_BIG5(num_labels=model_state_dict[\"classifier.weight\"].size()[0])\n",
        "  model.load_state_dict(model_state_dict)\n",
        "\n",
        "  epochs = checkpoint[\"epochs\"]\n",
        "  lowest_eval_loss = checkpoint[\"lowest_eval_loss\"]\n",
        "  train_loss_hist = checkpoint[\"train_loss_hist\"]\n",
        "  valid_loss_hist = checkpoint[\"valid_loss_hist\"]\n",
        "  \n",
        "  return model, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix2qAV7MA1Dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a01ef9-ad10-4d4f-ae6a-f3adc8fb0477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "#Define the optemizer, the learning rate and the weight decay\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24eCGFwzA1Dy",
        "outputId": "58fcc4bd-450b-4af9-85e3-18b2beb33fed"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.07577978054063321\n",
            "Valid loss: 0.03401650510230299\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   5%|▌         | 1/20 [16:58<5:22:28, 1018.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 0 with validation loss of 0.03401650510230299\n",
            "\n",
            "\n",
            "Train loss: 0.03749836801607645\n",
            "Valid loss: 0.03339392716245469\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 2/20 [33:36<5:02:00, 1006.69s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 1 with validation loss of 0.03339392716245469\n",
            "\n",
            "\n",
            "Train loss: 0.03607006206675491\n",
            "Valid loss: 0.03332759413009288\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  15%|█▌        | 3/20 [50:15<4:44:08, 1002.84s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 2 with validation loss of 0.03332759413009288\n",
            "\n",
            "\n",
            "Train loss: 0.0343210718039366\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 4/20 [1:06:50<4:26:40, 1000.06s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid loss: 0.03363639440534873\n",
            "\n",
            "\n",
            "Train loss: 0.031031275649826103\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  25%|██▌       | 5/20 [1:23:26<4:09:38, 998.58s/it] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid loss: 0.033831656980360024\n",
            "\n",
            "\n",
            "Train loss: 0.02721212798189175\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 6/20 [1:40:02<3:52:47, 997.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid loss: 0.03364173538911717\n",
            "\n",
            "\n",
            "Train loss: 0.023448641542801553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  35%|███▌      | 7/20 [1:56:38<3:36:02, 997.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid loss: 0.03344249094126169\n",
            "\n",
            "\n",
            "Train loss: 0.01983260258913262\n",
            "Valid loss: 0.03317237190526146\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 8/20 [2:13:17<3:19:30, 997.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 7 with validation loss of 0.03317237190526146\n",
            "\n",
            "\n",
            "Train loss: 0.01649349638932777\n",
            "Valid loss: 0.03295272796593942\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  45%|████▌     | 9/20 [2:29:55<3:02:57, 997.91s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 8 with validation loss of 0.03295272796593942\n",
            "\n",
            "\n",
            "Train loss: 0.0134889589858355\n",
            "Valid loss: 0.03278924507504433\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 10/20 [2:46:34<2:46:21, 998.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 9 with validation loss of 0.03278924507504433\n",
            "\n",
            "\n",
            "Train loss: 0.010846197792113285\n",
            "Valid loss: 0.03260557732124283\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  55%|█████▌    | 11/20 [3:03:13<2:29:45, 998.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 10 with validation loss of 0.03260557732124283\n",
            "\n",
            "\n",
            "Train loss: 0.008512571834243152\n",
            "Valid loss: 0.032496952389507956\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 12/20 [3:19:52<2:13:07, 998.49s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model at epoch 11 with validation loss of 0.032496952389507956\n",
            "\n",
            "\n",
            "Train loss: 0.006497149448808261\n",
            "Valid loss: 0.03236977822092676\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  65%|██████▌   | 13/20 [3:36:31<1:56:30, 998.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 12 with validation loss of 0.03236977822092676\n",
            "\n",
            "\n",
            "Train loss: 0.00477981110122775\n",
            "Valid loss: 0.03226642369573471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  70%|███████   | 14/20 [3:53:09<1:39:51, 998.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 13 with validation loss of 0.03226642369573471\n",
            "\n",
            "\n",
            "Train loss: 0.003401274373067103\n",
            "Valid loss: 0.03226317176633447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  75%|███████▌  | 15/20 [4:09:48<1:23:12, 998.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 14 with validation loss of 0.03226317176633447\n",
            "\n",
            "\n",
            "Train loss: 0.002334149602151321\n",
            "Valid loss: 0.032261354581924286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 16/20 [4:26:26<1:06:34, 998.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 15 with validation loss of 0.032261354581924286\n",
            "\n",
            "\n",
            "Train loss: 0.0015942168866016526\n",
            "Valid loss: 0.03225603537052097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  85%|████████▌ | 17/20 [4:43:05<49:56, 998.75s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model at epoch 16 with validation loss of 0.03225603537052097\n",
            "\n",
            "\n",
            "Train loss: 0.0010976909572183889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  90%|█████████ | 18/20 [4:59:41<33:15, 997.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.03231957634608547\n",
            "\n",
            "\n",
            "Train loss: 0.000775743217634711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  95%|█████████▌| 19/20 [5:16:17<16:37, 997.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.0323848969888801\n",
            "\n",
            "\n",
            "Train loss: 0.0005873433442882622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 20/20 [5:32:53<00:00, 998.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.032421887144548016\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model, train_loss_set, valid_loss_set = train(model=model,\\\n",
        "                                              num_epochs=num_epochs,\\\n",
        "                                              optimizer=optimizer,\\\n",
        "                                              train_dataloader=MLM_train_dataloader,\\\n",
        "                                              valid_dataloader=MLM_validation_dataloader,\\\n",
        "                                              model_save_path=model_save_path,\\\n",
        "                                              device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twZB4b1txn8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd391cd-e28b-4982-c21b-c07cd9c471ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#Restore the model best version \n",
        "#Define the training function : this code is copied from https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df\n",
        "\n",
        "checkpoint = torch.load(model_save_path)\n",
        "model_state_dict = checkpoint['state_dict']\n",
        "model = DistilBert_TGD_Ensemble_no_BIG5()\n",
        "model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device) # specify that our model will be runing on the specefied device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhIbAdjQ0Eos",
        "outputId": "1a316845-598e-48aa-ae0c-372e1335bc15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBert_TGD_Ensemble_no_BIG5(\n",
              "  (electra): DistilBertForMaskedLM(\n",
              "    (distilbert): DistilBertModel(\n",
              "      (embeddings): Embeddings(\n",
              "        (word_embeddings): Embedding(64356, 768)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (transformer): Transformer(\n",
              "        (layer): ModuleList(\n",
              "          (0): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (vocab_projector): Linear(in_features=768, out_features=64356, bias=True)\n",
              "    (mlm_loss_fct): CrossEntropyLoss()\n",
              "  )\n",
              "  (electra_mask_last): DistilBertForMaskedLM(\n",
              "    (distilbert): DistilBertModel(\n",
              "      (embeddings): Embeddings(\n",
              "        (word_embeddings): Embedding(64356, 768)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (transformer): Transformer(\n",
              "        (layer): ModuleList(\n",
              "          (0): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (vocab_projector): Linear(in_features=768, out_features=64356, bias=True)\n",
              "    (mlm_loss_fct): CrossEntropyLoss()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MDQlVgS51KV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27d5c2d7-57c7-42b1-8c42-72ca69933f0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Models/NextMovie/DistilBert_TGD_Ensemble_no_BIG5_last_masked_and_NormalMask_OnlyNextItemToPredict.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model_save_path #DistilBert_TGD_Ensemble_no_BIG5_last_masked_and_NormalMask_OnlyNextItemToPredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUP7GbZEz3bZ"
      },
      "outputs": [],
      "source": [
        "# define the word prediction function :\n",
        "#This code borrow ideas from  : https://colab.research.google.com/github/YuvalPeleg/transformers-workshop/blob/master/MLM.ipynb\n",
        "def word_prediction(text, model, tokenizer, topn=10,device=\"cuda\"):\n",
        "  tokenized_text = tokenizer.tokenize('[CLS] '+ text+ ' [SEP]')\n",
        "  masked_index = -1\n",
        "  for i, token in enumerate(tokenized_text):\n",
        "    if token=='[MASK]':\n",
        "      masked_index = i\n",
        "      break\n",
        "  assert i>=0\n",
        "\n",
        "  tok_t = torch.tensor([tokenizer.convert_tokens_to_ids(tokenized_text)]).to(device)\n",
        "  seg_t = torch.tensor([[0]*len(tokenized_text)]).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      out =model(input_ids=tok_t,input_ids_mask_last=tok_t)\n",
        "      pred = out[0]\n",
        "  pre_inds = torch.argsort(-pred[0, masked_index])\n",
        "  pred_tokens = tokenizer.convert_ids_to_tokens([ind.item() for ind in pre_inds])\n",
        "  pre_probs = [round(p.item(),4) for p in torch.softmax(pred[0, masked_index], 0)[pre_inds]]\n",
        "  l=list(zip(pred_tokens, pre_probs))[:topn]\n",
        "  ret=[c[0] for c in l]\n",
        "  return ret\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Collect the test sequences and maske the last token and use the masked token as the next movie label\n",
        "def get_test_data_and_labels(data,topn=1):\n",
        "  test=[]\n",
        "  labels=[]\n",
        "  for d in data:\n",
        "    splited=d.split()\n",
        "    labels.append(splited[-1])\n",
        "    test.append(\" \".join(x for x in splited[:-1])+\" [MASK]\")\n",
        "\n",
        "  return test,labels\n",
        "test,test_lab=get_test_data_and_labels(test_data,topn=5)"
      ],
      "metadata": {
        "id": "hLL0Ps8snEn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qskdw1ZjAVS"
      },
      "outputs": [],
      "source": [
        "# Define the Hit ratio function\n",
        "def hit_ratio(data_row,label,topn=1):\n",
        "\n",
        "  hit=0\n",
        " \n",
        "  predictions=word_prediction(data_row,model,tokenizer_4rec,topn=topn)\n",
        "  predicted_items=predictions\n",
        "  #print(f'label :{label}')\n",
        "  #print(f'predicted items :{predicted_items}')\n",
        "  if label in predicted_items:\n",
        "    hit=1\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  return hit\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL83iR6MjAVT"
      },
      "outputs": [],
      "source": [
        "# Define the Mean reciprocal rank function\n",
        "\n",
        "def MRR(data_row,label, topn=10):\n",
        "  mrr=0\n",
        " \n",
        "  predictions=word_prediction(data_row,model,tokenizer_4rec,topn=topn)\n",
        "  predicted_items=predictions\n",
        "  #print(f'label :{label}')\n",
        "  #print(f'predicted items :{predicted_items}')\n",
        "  if label in predicted_items:\n",
        "    mrr=1/(list(predicted_items).index(label)+1)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  return mrr\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the evaluation function for all instances\n",
        "def evaluation_all_users(data,topn=1,typee='HR'):\n",
        "  \n",
        "  test,test_lab=get_test_data_and_labels(data,topn=topn)\n",
        "\n",
        "  fc=hit_ratio\n",
        "  if typee=='MRR':\n",
        "    fc=MRR\n",
        "\n",
        "  all_hits=0\n",
        "  for i,row in enumerate(test):\n",
        "\n",
        "    user_hit=fc(row, test_lab[i],topn=topn)\n",
        "    all_hits=all_hits+user_hit\n",
        "  return all_hits/len(data)"
      ],
      "metadata": {
        "id": "JSyFgipVqbo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6cdccc5-289c-426c-c71c-93e42361c953",
        "id": "TDp60F_BjAVT"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07366984993178717"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "#MRR@1\n",
        "all_hits=evaluation_all_users(test_data,topn=1,typee='MRR')\n",
        "all_hits\n",
        "#0.07366984993178717"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MRR@3\n",
        "\n",
        "all_hits=evaluation_all_users(test_data,topn=3,typee='MRR')\n",
        "all_hits\n",
        "#0.08481127785356982"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK9Vj1635iC0",
        "outputId": "10b5386b-0627-4432-9309-f5bc1a0376d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08481127785356982"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MRR@5\n",
        "\n",
        "all_hits=evaluation_all_users(test_data,topn=5,typee='MRR')\n",
        "all_hits\n",
        "#0.0884947703501592\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmD4QAeu0Bxi",
        "outputId": "5ec436fc-decf-4bc1-d39a-8aff246f65e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08849477035015918"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MRR@10\n",
        "\n",
        "all_hits=evaluation_all_users(test_data,topn=10,typee='MRR')\n",
        "all_hits\n",
        "#0.09128121007384313\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5ZBEHkS5pha",
        "outputId": "11564af3-e5f4-4843-8562-6fba4b667ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09128121007384313"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HRR@1\n",
        "\n",
        "all_hits=evaluation_all_users(test_data,topn=1)\n",
        "all_hits\n",
        "#0.07366984993178717\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g95CH205uC0",
        "outputId": "f0d0a7d3-f277-41f0-d9f4-e0021801a976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07366984993178717"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HRR@3\n",
        "\n",
        "all_hits=evaluation_all_users(test_data,topn=3)\n",
        "all_hits\n",
        "#0.09959072305593451\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWgcsv2h5zVP",
        "outputId": "f25b96a5-0eff-4df5-f49a-6af3292ebd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09959072305593451"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HRR@5\n",
        "\n",
        "all_hits=evaluation_all_users(test_data,topn=5)\n",
        "all_hits\n",
        "#0.11596180081855388\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz5pwnw0509G",
        "outputId": "512f6d37-70ec-47a8-b804-6372511f041a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11596180081855388"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HRR@10\n",
        "\n",
        "all_hits=evaluation_all_users(test_data,topn=10)\n",
        "all_hits\n",
        "#0.1364256480218281"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJX2I8bn51-Q",
        "outputId": "30687df2-f224-405a-a483-9add3db39ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1364256480218281"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PC6CbO1T52-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TheNextMovieToWatch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5725cf74f3f64775ae71290742038ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17937c0a4f194cdaaa6c0ca083671d90",
              "IPY_MODEL_fdef7074008e47579d630f9a9d033578",
              "IPY_MODEL_ab2fd22206064cc1bc7ccefeb9867b83"
            ],
            "layout": "IPY_MODEL_b92f7d57097547ea888476fe12608059"
          }
        },
        "17937c0a4f194cdaaa6c0ca083671d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb6e7028d104829a4787bffc3438ede",
            "placeholder": "​",
            "style": "IPY_MODEL_fc1bdf6187124f1aa5c416833c2a1eb6",
            "value": "Downloading: 100%"
          }
        },
        "fdef7074008e47579d630f9a9d033578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f59da6f3fd4e04a3b372a7ee444b03",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_176489304bf745dbaa7a2e85d42abb2d",
            "value": 231508
          }
        },
        "ab2fd22206064cc1bc7ccefeb9867b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb42fe2393bb417ba2c8c275882e9331",
            "placeholder": "​",
            "style": "IPY_MODEL_a5b2d2293b3f433b841a15cf78ca4b30",
            "value": " 226k/226k [00:00&lt;00:00, 284kB/s]"
          }
        },
        "b92f7d57097547ea888476fe12608059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb6e7028d104829a4787bffc3438ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc1bdf6187124f1aa5c416833c2a1eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9f59da6f3fd4e04a3b372a7ee444b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "176489304bf745dbaa7a2e85d42abb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb42fe2393bb417ba2c8c275882e9331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b2d2293b3f433b841a15cf78ca4b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c79cdc4883b241b39a8d3585cdccbd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_985cada323ee456b9450e26562af8939",
              "IPY_MODEL_d2adcd244c4f4defbc9426df5a7fe893",
              "IPY_MODEL_396255faa03245c4b17f27c0018c1420"
            ],
            "layout": "IPY_MODEL_4c59c1de03764422aa88df9d01be3264"
          }
        },
        "985cada323ee456b9450e26562af8939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e28f4e9881c94753a36ffa8d6aabc4a4",
            "placeholder": "​",
            "style": "IPY_MODEL_8df13ed85dc94e0caa7a318bd6e40d18",
            "value": "Downloading: 100%"
          }
        },
        "d2adcd244c4f4defbc9426df5a7fe893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c2e4519fa6f451e96df850b8b6f5c3f",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29fafae2e9b8410baa498f541c6797f6",
            "value": 28
          }
        },
        "396255faa03245c4b17f27c0018c1420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b08323ff0b744687bf29dbb92d8e3a13",
            "placeholder": "​",
            "style": "IPY_MODEL_de0041f0571048159dbc4bb420abf1d6",
            "value": " 28.0/28.0 [00:00&lt;00:00, 933B/s]"
          }
        },
        "4c59c1de03764422aa88df9d01be3264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28f4e9881c94753a36ffa8d6aabc4a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df13ed85dc94e0caa7a318bd6e40d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c2e4519fa6f451e96df850b8b6f5c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29fafae2e9b8410baa498f541c6797f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b08323ff0b744687bf29dbb92d8e3a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0041f0571048159dbc4bb420abf1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fac72d0b8b7544f0823eb4341b7a0c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3263d8fefd6c4b46911f60786f82829e",
              "IPY_MODEL_ad6878793872432d8de0c146a0c717b7",
              "IPY_MODEL_2f15fade43554ce5a502d43a07e76d9d"
            ],
            "layout": "IPY_MODEL_9cbe54f357aa49bb9b815d68766d28fa"
          }
        },
        "3263d8fefd6c4b46911f60786f82829e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa474595e1b244c3a823d5abd8f9a15a",
            "placeholder": "​",
            "style": "IPY_MODEL_e6b84502351443c79d80dfd402094f1f",
            "value": "Downloading: 100%"
          }
        },
        "ad6878793872432d8de0c146a0c717b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_412561628438416db915e58d2c4e57b0",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d9ad211477a45a687c3f2d54ddb8472",
            "value": 483
          }
        },
        "2f15fade43554ce5a502d43a07e76d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e22af82d7774125a57cc958bff342bb",
            "placeholder": "​",
            "style": "IPY_MODEL_34a91dc2e4154bb7b37d650818ac124a",
            "value": " 483/483 [00:00&lt;00:00, 14.7kB/s]"
          }
        },
        "9cbe54f357aa49bb9b815d68766d28fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa474595e1b244c3a823d5abd8f9a15a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b84502351443c79d80dfd402094f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "412561628438416db915e58d2c4e57b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9ad211477a45a687c3f2d54ddb8472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e22af82d7774125a57cc958bff342bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a91dc2e4154bb7b37d650818ac124a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50e78c239b74430ba55843387dc3a169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e316a1efa9734671b2b51702497fc523",
              "IPY_MODEL_d0a4d25ae00d4e16a34bf6212d9b06a5",
              "IPY_MODEL_b9da2ce48e0d43708af23c9c46462f48"
            ],
            "layout": "IPY_MODEL_169d9b88fca84987831632dadf05c369"
          }
        },
        "e316a1efa9734671b2b51702497fc523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287bba878a724b63b5ab403437ed6808",
            "placeholder": "​",
            "style": "IPY_MODEL_308e07b431ea440cbeabed22dfa0c736",
            "value": "Downloading: 100%"
          }
        },
        "d0a4d25ae00d4e16a34bf6212d9b06a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b61d35a5a7e4a2fa9b9dcb66a2e54d6",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3d12db0406d4ae9b778c34038746b8f",
            "value": 267967963
          }
        },
        "b9da2ce48e0d43708af23c9c46462f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07639f7954f745eeb6166943745df805",
            "placeholder": "​",
            "style": "IPY_MODEL_1f1795092eb8422db7723ecd434a4346",
            "value": " 256M/256M [00:04&lt;00:00, 56.0MB/s]"
          }
        },
        "169d9b88fca84987831632dadf05c369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "287bba878a724b63b5ab403437ed6808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308e07b431ea440cbeabed22dfa0c736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b61d35a5a7e4a2fa9b9dcb66a2e54d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d12db0406d4ae9b778c34038746b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07639f7954f745eeb6166943745df805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1795092eb8422db7723ecd434a4346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}